import streamlit as st
import pandas as pd
import re
from docx import Document
from docx.shared import Pt, Cm
from docx.oxml.ns import qn
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_CELL_VERTICAL_ALIGNMENT, WD_ROW_HEIGHT_RULE
from docx.oxml import OxmlElement
import io

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="æ™ºèƒ½è´¢åŠ¡åˆ†æç³»ç»Ÿ", 
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# ================= 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° =================

def set_cell_border(cell, **kwargs):
    """è®¾ç½®å•å…ƒæ ¼è¾¹æ¡†"""
    tc = cell._tc
    tcPr = tc.get_or_add_tcPr()
    for border_name in ["top", "left", "bottom", "right", "insideH", "insideV"]:
        if border_name in kwargs:
            edge = kwargs[border_name]
            tcBorders = tcPr.first_child_found_in("w:tcBorders")
            if tcBorders is None:
                tcBorders = OxmlElement('w:tcBorders')
                tcPr.append(tcBorders)
            border = OxmlElement(f'w:{border_name}')
            border.set(qn('w:val'), edge.get('val', 'single'))
            border.set(qn('w:sz'), str(edge.get('sz', 4)))
            border.set(qn('w:space'), str(edge.get('space', 0)))
            border.set(qn('w:color'), edge.get('color', 'auto'))
            tcBorders.append(border)

def create_word_table_file(df, title="æ•°æ®è¡¨", bold_rows=None):
    """ğŸ”¥ ç”Ÿæˆç²¾æ’ç‰ˆ Word è¡¨æ ¼"""
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
    style.font.size = Pt(10.5)

    heading = doc.add_heading(title, level=1)
    heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in heading.runs:
        run.font.name = 'Times New Roman'
        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“') 
        run.font.bold = True
        run.font.color.rgb = None

    export_df = df.reset_index()
    table = doc.add_table(rows=1, cols=len(export_df.columns))
    table.alignment = WD_ALIGN_PARAGRAPH.CENTER
    table.autofit = False 
    
    col_widths = [Cm(6.0)] + [Cm(3.0)] * (len(export_df.columns) - 1)
    for i, width in enumerate(col_widths):
        for row in table.rows:
            row.cells[i].width = width

    hdr_cells = table.rows[0].cells
    table.rows[0].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
    table.rows[0].height = Cm(1.0)

    for i, col_name in enumerate(export_df.columns):
        cell = hdr_cells[i]
        cell.text = str(col_name)
        set_cell_border(cell, top={"val": "single", "sz": 12}, bottom={"val": "single", "sz": 12}, left={"val": "single", "sz": 4}, right={"val": "single", "sz": 4})
        cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
        paragraph = cell.paragraphs[0]
        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER 
        for run in paragraph.runs:
            run.font.bold = True
            run.font.size = Pt(10.5)
            run.font.name = 'Times New Roman'
            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

    for r_idx, row in export_df.iterrows():
        row_cells = table.add_row().cells
        table.rows[r_idx+1].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
        table.rows[r_idx+1].height = Cm(0.8)
        subject_name = str(row[0]).strip()
        is_bold = False
        if bold_rows and subject_name in bold_rows: is_bold = True
        elif any(k in subject_name for k in ["åˆè®¡", "æ€»è®¡", "å‡€é¢", "å‡€å¢åŠ é¢", "æ„æˆ", "æ´»åŠ¨"]): is_bold = True
        elif subject_name.endswith("ï¼š") or subject_name.endswith(":"): is_bold = True

        for i, val in enumerate(row):
            cell = row_cells[i]
            cell.text = str(val) if pd.notna(val) and val != "" else ""
            bottom_sz = 12 if r_idx == len(export_df) - 1 else 4
            set_cell_border(cell, top={"val": "single", "sz": 4}, bottom={"val": "single", "sz": bottom_sz}, left={"val": "single", "sz": 4}, right={"val": "single", "sz": 4})
            cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
            paragraph = cell.paragraphs[0]
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            for run in paragraph.runs:
                run.font.size = Pt(10.5)
                run.font.name = 'Times New Roman'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                if is_bold: run.font.bold = True
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def create_excel_file(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='æ•°æ®æ˜ç»†')
    output.seek(0)
    return output

def load_single_word(file_obj):
    try:
        file_obj.seek(0)
        doc = Document(file_obj)
        full_text = []
        for p in doc.paragraphs:
            txt = p.text.strip()
            if len(txt) > 2: full_text.append(txt)
        for table in doc.tables:
            for row in table.rows:
                row_text = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                if row_text: full_text.append(" | ".join(row_text))
            full_text.append("\n")
        return "\n".join(full_text), True, ""
    except Exception as e:
        return "", False, f"âŒ è¯»å–å¤±è´¥: {str(e)}"

def find_context(subject, word_data_list):
    if not word_data_list: return ""
    clean_sub = subject.replace(" ", "")
    found_contexts = []
    for item in word_data_list:
        content = item['content']
        source = item['source']
        matches = list(re.finditer(re.escape(clean_sub), content))
        if matches:
            top_matches = matches[:3] 
            file_context = []
            for m in top_matches:
                idx = m.start()
                start = max(0, idx - 300)
                end = min(len(content), idx + 800)
                ctx = content[start:end].replace('\n', ' ')
                file_context.append(f"...{ctx}...")
            combined_ctx = "\n\n----------\n\n".join(file_context)
            found_contexts.append(f"ğŸ“„ **æ¥æºï¼š{source}**\n{combined_ctx}")
    return "\n\n====================\n\n".join(found_contexts)

def extract_date_label(header_str):
    s = str(header_str).strip()
    match = re.search(r'[ã€\[](.*?)[ã€‘\]]', s)
    if match: return match.group(1)
    year = re.search(r'(\d{4})', s)
    if year: return f"{year.group(1)}å¹´"
    return s

def safe_pct(num, denom):
    return (num / denom * 100) if denom != 0 and pd.notna(num) and pd.notna(denom) else 0.0

def fuzzy_load_excel(file_obj, sheet_name, header_row=None):
    try:
        xl = pd.ExcelFile(file_obj)
        all_sheet_names = xl.sheet_names
        target_sheet = None
        
        if sheet_name in all_sheet_names:
            target_sheet = sheet_name
        else:
            clean_target = sheet_name.replace(" ", "")
            for actual_name in all_sheet_names:
                if actual_name.replace(" ", "") == clean_target:
                    target_sheet = actual_name
                    st.toast(f"âš ï¸ è‡ªåŠ¨ä¿®æ­£ Sheet åä¸ºï¼š'{actual_name}'")
                    break
        
        if target_sheet is None:
            return None, all_sheet_names

        # è´¢åŠ¡æŒ‡æ ‡è¡¨ç‰¹ä¾›é€»è¾‘
        if "è´¢åŠ¡æŒ‡æ ‡" in sheet_name or "5-3" in sheet_name:
            return smart_load_ratios(file_obj, target_sheet)
        
        return pd.read_excel(file_obj, sheet_name=target_sheet, header=header_row), None

    except Exception as e:
        return None, [str(e)]

def smart_load_ratios(file_obj, sheet_name):
    try:
        df_raw = pd.read_excel(file_obj, sheet_name=sheet_name, header=None)
        header_idx = -1
        for i in range(10):
            row_values = df_raw.iloc[i].astype(str).values
            if any("é¡¹ç›®" in v or "æŒ‡æ ‡" in v for v in row_values):
                header_idx = i
                break
        if header_idx == -1: header_idx = 1
        df = pd.read_excel(file_obj, sheet_name=sheet_name, header=header_idx)
        cols = df.columns.tolist()
        date_col_indices = []
        for idx, col_name in enumerate(cols):
            s = str(col_name)
            if "å¹´" in s or "T" in s or "202" in s or "æœŸ" in s:
                date_col_indices.append(idx)
        if len(date_col_indices) >= 3:
            target_cols = [0] + date_col_indices[:3]
        else:
            target_cols = [0, 2, 3, 4]
        df_final = df.iloc[:, target_cols]
        orig_cols = df_final.columns.tolist()
        d_labels = [extract_date_label(c) for c in orig_cols[1:]]
        df_final.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
        df_final = df_final.dropna(subset=['ç§‘ç›®'])
        df_final['ç§‘ç›®'] = df_final['ç§‘ç›®'].astype(str).str.strip()
        for c in ['T', 'T_1', 'T_2']:
            df_final[c] = pd.to_numeric(df_final[c], errors='coerce').fillna(0)
        df_final.set_index('ç§‘ç›®', inplace=True)
        return df_final, d_labels
    except Exception as e:
        raise Exception(f"æ™ºèƒ½è¯»å–å¤±è´¥: {str(e)}")

def find_row_fuzzy(df, keywords, exclude_keywords=None, default_val=None):
    if isinstance(keywords, str): keywords = [keywords]
    clean_index = df.index.astype(str).str.replace(r'\s+', '', regex=True)
    found_rows = []
    for kw in keywords:
        clean_kw = kw.replace(" ", "")
        mask_exact = clean_index == clean_kw
        mask_contains = clean_index.str.contains(clean_kw, case=False, na=False)
        if exclude_keywords:
            for ex_kw in exclude_keywords:
                clean_ex = ex_kw.replace(" ", "")
                mask_contains = mask_contains & (~clean_index.str.contains(clean_ex, case=False, na=False))
        matched_indices = df.index[mask_exact | mask_contains].tolist()
        for idx in matched_indices:
            row = df.loc[idx]
            if isinstance(row, pd.DataFrame):
                for _, r in row.iterrows(): found_rows.append(r)
            else:
                found_rows.append(row)
    best_row = None
    max_non_zeros = -1
    for row in found_rows:
        non_zeros = 0
        if row['T'] != 0 and pd.notna(row['T']): non_zeros += 1
        if row['T_1'] != 0 and pd.notna(row['T_1']): non_zeros += 1
        if row['T_2'] != 0 and pd.notna(row['T_2']): non_zeros += 1
        if non_zeros > max_non_zeros:
            max_non_zeros = non_zeros
            best_row = row
    if best_row is not None: return best_row
    if default_val is not None: return default_val
    return pd.Series(0, index=df.columns)

def find_index_fuzzy(df, keywords):
    if isinstance(keywords, str): keywords = [keywords]
    clean_index = df.index.astype(str).str.replace(r'\s+', '', regex=True)
    for kw in keywords:
        clean_kw = kw.replace(" ", "")
        mask = clean_index.str.contains(clean_kw, case=False, na=False)
        if mask.any(): return df.index.get_loc(df.index[mask][0])
    return None

def smart_scale_convert(val, subject_name="", is_ebitda=False, is_ratio=False):
    if pd.isna(val) or val == 0: return 0.0
    if "äº¿å…ƒ" in subject_name: return val * 10000.0
    if "ä¸‡å…ƒ" in subject_name: return val
    if "å…ƒ" in subject_name and "ä¸‡å…ƒ" not in subject_name and "äº¿å…ƒ" not in subject_name: return val / 10000.0
    if is_ebitda:
        if abs(val) > 1000000: return val / 10000.0
        else: return val
    if is_ratio:
        if abs(val) < 1.0: return val * 100.0
        return val
    return val

# ================= 3. ä¸šåŠ¡é€»è¾‘ =================
def process_analysis_tab(df_raw, word_data_list, total_col_name, analysis_name, d_labels):
    try:
        if analysis_name == "è´Ÿå€º":
             index_series = df_raw.index.astype(str)
             clean_index = index_series.str.replace(r'\s+', '', regex=True)
             clean_target = total_col_name.replace(" ", "")
             match_mask = (clean_index == clean_target)
             if match_mask.any():
                 target_label = df_raw.index[match_mask][0]
                 idx_pos = df_raw.index.get_loc(target_label)
                 if isinstance(idx_pos, slice): idx_pos = idx_pos.stop - 1
                 elif hasattr(idx_pos, '__iter__'): idx_pos = idx_pos[-1]
                 if isinstance(idx_pos, int): df_raw = df_raw.iloc[:idx_pos + 1]
        
        total_row = find_row_fuzzy(df_raw, [total_col_name])
        if total_row.sum() == 0 and total_row.name is None:
             st.error(f"âŒ æœªæ‰¾åˆ°åˆè®¡è¡Œï¼š{total_col_name}")
             return
    except Exception as e:
        st.error(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {e}")
        return

    df = df_raw.copy()
    for period in ['T', 'T_1', 'T_2']:
        total = total_row[period]
        if total != 0: df[f'å æ¯”_{period}'] = df[period] / total
        else: df[f'å æ¯”_{period}'] = 0.0

    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ æ˜ç»†æ•°æ®", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ“ å˜åŠ¨åˆ†ææ–‡æ¡ˆ"])

    with tab1:
        c1, c2, c3 = st.columns([6, 1.2, 1.2]) 
        with c1: st.markdown(f"### {analysis_name}ç»“æ„æ˜ç»†")
        display_df = df.copy()
        for p in ['T', 'T_1', 'T_2']:
            display_df[f'fmt_{p}'] = display_df[p].apply(lambda x: f"{x:,.2f}")
            display_df[f'fmt_pct_{p}'] = (display_df[f'å æ¯”_{p}'] * 100).apply(lambda x: f"{x:.2f}")
        d_t, d_t1, d_t2 = d_labels
        final_df = pd.DataFrame(index=display_df.index)
        final_df[f"{d_t}"] = display_df['fmt_T']
        final_df["å æ¯”(%) "] = display_df['fmt_pct_T']
        final_df[f"{d_t1}"] = display_df['fmt_T_1']
        final_df["å æ¯”(%)"] = display_df['fmt_pct_T_1']
        final_df[f"{d_t2}"] = display_df['fmt_T_2']
        final_df[" å æ¯”(%)"] = display_df['fmt_pct_T_2']
        
        # ğŸŸ¢ æ¸…ç©ºä»¥å†’å·ç»“å°¾çš„æ ‡é¢˜è¡Œæ•°æ®ï¼ˆå¦‚â€œæµåŠ¨èµ„äº§ï¼šâ€ï¼‰
        for idx in final_df.index:
            if str(idx).strip().endswith("ï¼š") or str(idx).strip().endswith(":"):
                final_df.loc[idx] = ""

        with c2:
            doc_file = create_word_table_file(final_df, title=f"{analysis_name}ç»“æ„æƒ…å†µè¡¨")
            st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, f"{analysis_name}æ˜ç»†.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file = create_excel_file(final_df)
            st.download_button(f"ğŸ“¥ ä¸‹è½½ Excel", excel_file, f"{analysis_name}æ˜ç»†.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(final_df, use_container_width=True)

    with tab2:
        top_5 = df.sort_values(by='T', ascending=False).head(5).index.tolist()
        text = ""
        try:
            if analysis_name == "èµ„äº§":
                curr_row = find_row_fuzzy(df_raw, ['æµåŠ¨èµ„äº§åˆè®¡', 'æµåŠ¨èµ„äº§å°è®¡'])
                non_curr_row = find_row_fuzzy(df_raw, ['éæµåŠ¨èµ„äº§åˆè®¡', 'éæµåŠ¨èµ„äº§å°è®¡'])
                text = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººèµ„äº§æ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                        f"å…¶ä¸­ï¼ŒæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{curr_row['T_2']:,.2f}ä¸‡å…ƒã€{curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                        f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(curr_row['T_2'], total_row['T_2']):.2f}%ã€{safe_pct(curr_row['T_1'], total_row['T_1']):.2f}%å’Œ{safe_pct(curr_row['T'], total_row['T']):.2f}%ï¼›\n\n"
                        f"éæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{non_curr_row['T_2']:,.2f}ä¸‡å…ƒã€{non_curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{non_curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                        f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(non_curr_row['T_2'], total_row['T_2']):.2f}%ã€{safe_pct(non_curr_row['T_1'], total_row['T_1']):.2f}%å’Œ{safe_pct(non_curr_row['T'], total_row['T']):.2f}%ã€‚\n\n"
                        f"åœ¨æ€»èµ„äº§æ„æˆä¸­ï¼Œå…¬å¸èµ„äº§ä¸»è¦ä¸º **{'ã€'.join(top_5)}** ç­‰ã€‚")
            elif analysis_name == "è´Ÿå€º":
                curr_row = find_row_fuzzy(df_raw, ['æµåŠ¨è´Ÿå€ºåˆè®¡', 'æµåŠ¨è´Ÿå€ºå°è®¡'])
                non_curr_row = find_row_fuzzy(df_raw, ['éæµåŠ¨è´Ÿå€ºåˆè®¡', 'éæµåŠ¨è´Ÿå€ºå°è®¡'])
                diff_prev = total_row['T_1'] - total_row['T_2']
                pct_prev = safe_pct(diff_prev, total_row['T_2'])
                dir_prev = "å¢åŠ " if diff_prev >= 0 else "å‡å°‘"
                label_prev = "å¢å¹…" if diff_prev >= 0 else "é™å¹…"
                diff_curr = total_row['T'] - total_row['T_1']
                pct_curr = safe_pct(diff_curr, total_row['T_1'])
                dir_curr = "å¢åŠ " if diff_curr >= 0 else "å‡å°‘"
                label_curr = "å¢å¹…" if diff_curr >= 0 else "é™å¹…"
                trend_desc = "å¢é•¿" if diff_curr >= 0 else "ä¸‹é™"
                text = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººè´Ÿå€ºæ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                        f"{d_labels[1]}è¾ƒ{d_labels[2]}{dir_prev}{abs(diff_prev):,.2f}ä¸‡å…ƒï¼Œ{label_prev}{abs(pct_prev):.2f}%ï¼›"
                        f"{d_labels[0]}å‘è¡Œäººè´Ÿå€ºè¾ƒ{d_labels[1]}{dir_curr}{abs(diff_curr):,.2f}ä¸‡å…ƒï¼Œ{label_curr}{abs(pct_curr):.2f}%ã€‚"
                        f"æŠ¥å‘ŠæœŸå†…å‘è¡Œäººçš„è´Ÿå€ºè§„æ¨¡å‘ˆç°{trend_desc}æ€åŠ¿ï¼Œä¸»è¦åŸå› ä¸ºå‘è¡Œäººï¼ˆç”¨æˆ·è‡ªè¡Œåˆ†æï¼‰ã€‚\n\n"
                        f"ä»è´Ÿå€ºç»“æ„æ¥çœ‹ï¼ŒæŠ¥å‘ŠæœŸå†…ï¼ŒæµåŠ¨è´Ÿå€ºåˆ†åˆ«ä¸º{curr_row['T_2']:,.2f}ä¸‡å…ƒã€{curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                        f"å è´Ÿå€ºæ€»é¢æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(curr_row['T_2'], total_row['T_2']):.2f}%ã€{safe_pct(curr_row['T_1'], total_row['T_1']):.2f}%å’Œ{safe_pct(curr_row['T'], total_row['T']):.2f}%ï¼Œ"
                        f"ä¸»è¦ç”± **{'ã€'.join(top_5)}** ç­‰æ„æˆï¼›\n\n"
                        f"éæµåŠ¨è´Ÿå€ºåˆ†åˆ«ä¸º{non_curr_row['T_2']:,.2f}ä¸‡å…ƒã€{non_curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{non_curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                        f"å è´Ÿå€ºæ€»é¢æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(non_curr_row['T_2'], total_row['T_2']):.2f}%ã€{safe_pct(non_curr_row['T_1'], total_row['T_1']):.2f}%å’Œ{safe_pct(non_curr_row['T'], total_row['T']):.2f}%ã€‚")
            
            with st.container(border=True):
                st.markdown(f"#### ğŸ“ {analysis_name}ç»¼è¿°æ–‡æ¡ˆ")
                st.markdown(text)
                st.code(text, language='text')

        except Exception as e:
             st.error(f"ç”Ÿæˆæ–‡æ¡ˆå‡ºé”™: {e}")

    with tab3:
        latest_date_label = d_labels[0]
        st.info(f"ğŸ’¡ **æç¤º**ï¼šå·²æ ¹æ®æ•°æ®ç”Ÿæˆç§‘ç›®å˜åŠ¨åˆ†ææ–‡æ¡ˆè‰ç¨¿ã€‚")
        exclude_list = ['åˆè®¡', 'æ€»è®¡', 'æ€»é¢']
        major_subjects = df[(df['å æ¯”_T'] > 0.01) & (~df.index.str.contains('|'.join(exclude_list)))].index.tolist()
        denom_text = "æ€»èµ„äº§" if analysis_name == "èµ„äº§" else f"{analysis_name}æ€»é¢"
        
        for subject in major_subjects:
            row = df.loc[subject]
            diff_prev = row['T_1'] - row['T_2']
            pct_prev = safe_pct(diff_prev, row['T_2'])
            dir_prev = "å¢åŠ " if diff_prev >= 0 else "å‡å°‘"
            label_prev = "å¢å¹…" if diff_prev >= 0 else "é™å¹…"
            diff_curr = row['T'] - row['T_1']
            pct_curr = safe_pct(diff_curr, row['T_1'])
            dir_curr = "å¢åŠ " if diff_curr >= 0 else "å‡å°‘"
            label_curr = "å¢å¹…" if diff_curr >= 0 else "é™å¹…"
            
            # ç”Ÿæˆå˜åŠ¨åˆ†ææ–‡æ¡ˆ
            analysis_text = (f"æŠ¥å‘ŠæœŸå„æœŸæœ«ï¼Œå‘è¡Œäºº{subject}ä½™é¢åˆ†åˆ«ä¸º{row['T_2']:,.2f}ä¸‡å…ƒã€{row['T_1']:,.2f}ä¸‡å…ƒå’Œ{row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                           f"å {denom_text}çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{row['å æ¯”_T_2']*100:.2f}%ã€{row['å æ¯”_T_1']*100:.2f}%å’Œ{row['å æ¯”_T']*100:.2f}%ã€‚\n\n"
                           f"{d_t1}æœ«ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_t2}æœ«{dir_prev}{abs(diff_prev):,.2f}ä¸‡å…ƒï¼Œ{label_prev}{abs(pct_prev):.2f}%ï¼›"
                           f"{d_t}æœ«ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_t1}æœ«{dir_curr}{abs(diff_curr):,.2f}ä¸‡å…ƒï¼Œ{label_curr}{abs(pct_curr):.2f}%ã€‚\n\n"
                           f"å˜åŠ¨ä¸»è¦åŸå› ä¸ºï¼šï¼ˆè¯·åœ¨æ­¤å¤„è¡¥å……å…·ä½“çš„ä¸šåŠ¡åŸå› ï¼Œä¾‹å¦‚ï¼šä¸šåŠ¡è§„æ¨¡æ‰©å¤§/ç¼©å‡ã€æ–°å¢/å¿è¿˜æ¬¾é¡¹ç­‰ï¼‰ã€‚")
            
            # å¦‚æœæœ‰é™„æ³¨ä¸Šä¸‹æ–‡ï¼Œå±•ç¤ºåœ¨ä¸‹æ–¹ä¾›å‚è€ƒ
            ctx = find_context(subject, word_data_list)
            if ctx:
                analysis_text += f"\n\nã€å‚è€ƒé™„æ³¨ä¿¡æ¯ã€‘\n{ctx}"

            with st.expander(f"ğŸ“Œ {subject} (å æ¯” {row['å æ¯”_T']:.2%} @ {latest_date_label})"):
                st.markdown(analysis_text)
                st.code(analysis_text, language='text')

# ================= 4. ä¸šåŠ¡é€»è¾‘ï¼šç°é‡‘æµé‡ =================
def calculate_cash_flow_percentages(df_raw, d_labels):
    data_list = []
    d_t, d_t1, d_t2 = d_labels
    sections = [
        (["ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡", "ä¸€ã€ç»è¥æ´»åŠ¨"], ["ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], "ä¸€ã€ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥æ„æˆ"),
        (["ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], ["ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"], "äºŒã€ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºæ„æˆ"),
        (["æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡", "äºŒã€æŠ•èµ„æ´»åŠ¨"], ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], "ä¸‰ã€æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥æ„æˆ"),
        (["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"], "å››ã€æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºæ„æˆ"),
        (["ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡", "ä¸‰ã€ç­¹èµ„æ´»åŠ¨"], ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], "äº”ã€ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥æ„æˆ"),
        (["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"], ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"], "å…­ã€ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºæ„æˆ"),
    ]
    for start_kws, end_kws, cat_name in sections:
        data_list.append([cat_name, "", "", ""])
        idx_start = find_index_fuzzy(df_raw, start_kws)
        idx_end = find_index_fuzzy(df_raw, end_kws)
        if idx_start is not None and idx_end is not None and idx_end > idx_start:
            denom_row = df_raw.iloc[idx_end]
            subset = df_raw.iloc[idx_start+1 : idx_end]
            for i in range(len(subset)):
                row = subset.iloc[i]
                subject = row.name
                if not isinstance(subject, str) or len(subject.strip()) < 2: continue
                pct_t = safe_pct(row['T'], denom_row['T'])
                pct_t1 = safe_pct(row['T_1'], denom_row['T_1'])
                pct_t2 = safe_pct(row['T_2'], denom_row['T_2'])
                data_list.append([subject, f"{pct_t:.2f}%", f"{pct_t1:.2f}%", f"{pct_t2:.2f}%"])
    return pd.DataFrame(data_list, columns=["é¡¹ç›®", f"{d_t}å æ¯”", f"{d_t1}å æ¯”", f"{d_t2}å æ¯”"]).set_index("é¡¹ç›®")

def process_cash_flow_tab(df_raw, word_data_list, d_labels):
    d_t, d_t1, d_t2 = d_labels
    structure = [("ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡ï¼š", None), ("ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡", ["ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"]), ("ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡", ["ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"]), ("ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢", ["ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"]), ("æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡ï¼š", None), ("æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡", ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"]), ("æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡", ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"]), ("æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢", ["æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"]), ("ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡ï¼š", None), ("ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡", ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"]), ("ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡", ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"]), ("ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢", ["ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"]), ("ç°é‡‘åŠç°é‡‘ç­‰ä»·ç‰©å‡€å¢åŠ é¢", ["ç°é‡‘åŠç°é‡‘ç­‰ä»·ç‰©å‡€å¢åŠ é¢"])]
    data_list = []
    for display_name, keywords in structure:
        if keywords is None: data_list.append([display_name, "", "", ""])
        else:
            row = find_row_fuzzy(df_raw, keywords)
            if row.name is None: val_t, val_t1, val_t2 = 0, 0, 0
            else: val_t, val_t1, val_t2 = row['T'], row['T_1'], row['T_2']
            data_list.append([display_name, f"{val_t:,.2f}" if val_t!="" else "", f"{val_t1:,.2f}" if val_t1!="" else "", f"{val_t2:,.2f}" if val_t2!="" else ""])
    df_display = pd.DataFrame(data_list, columns=["é¡¹ç›®", d_t, d_t1, d_t2])
    df_display.set_index("é¡¹ç›®", inplace=True)

    df_pct = calculate_cash_flow_percentages(df_raw, d_labels)

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ æ‘˜è¦æ•°æ®", "ğŸ“Š å æ¯”åˆ†æ", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ“ å˜åŠ¨åˆ†ææ–‡æ¡ˆ"])
    
    with tab1:
        c1, c2, c3 = st.columns([6, 1.2, 1.2]) 
        with c1: st.markdown("### ç°é‡‘æµé‡ç»“æ„æ˜ç»†")
        with c2:
            doc_file = create_word_table_file(df_display, title="ç°é‡‘æµé‡è¡¨æ‘˜è¦")
            st.download_button("ğŸ“¥ ä¸‹è½½ Word", doc_file, "ç°é‡‘æµé‡è¡¨.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file = create_excel_file(df_display)
            st.download_button("ğŸ“¥ ä¸‹è½½ Excel", excel_file, "ç°é‡‘æµé‡è¡¨.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(df_display, use_container_width=True)

    with tab2:
        c1, c2 = st.columns([6, 1.5])
        with c1: st.markdown("### å„é¡¹æ´»åŠ¨ç°é‡‘æµå æ¯”åˆ†æ")
        with c2:
            doc_pct = create_word_table_file(df_pct, title="ç°é‡‘æµé‡å æ¯”è¡¨")
            st.download_button("ğŸ“¥ ä¸‹è½½å æ¯”è¡¨ Word", doc_pct, "ç°é‡‘æµå æ¯”.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        st.info("ğŸ’¡ è¯´æ˜ï¼šæµå…¥é¡¹å æ¯” = ç§‘ç›®/æµå…¥å°è®¡ï¼›æµå‡ºé¡¹å æ¯” = ç§‘ç›®/æµå‡ºå°è®¡")
        st.dataframe(df_pct, use_container_width=True)

    with tab3:
        op_in_total = find_row_fuzzy(df_raw, ["ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"])
        op_out_total = find_row_fuzzy(df_raw, ["ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"])
        op_net = find_row_fuzzy(df_raw, ["ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"])
        op_sales = find_row_fuzzy(df_raw, ["é”€å”®å•†å“ã€æä¾›åŠ³åŠ¡æ”¶åˆ°çš„ç°é‡‘"])
        op_other_in = find_row_fuzzy(df_raw, ["æ”¶åˆ°å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘"])
        op_buy = find_row_fuzzy(df_raw, ["è´­ä¹°å•†å“ã€æ¥å—åŠ³åŠ¡æ”¯ä»˜çš„ç°é‡‘"])
        op_other_out = find_row_fuzzy(df_raw, ["æ”¯ä»˜å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘"])
        inv_net = find_row_fuzzy(df_raw, ["æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"])
        inv_in_total = find_row_fuzzy(df_raw, ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"])
        inv_out_total = find_row_fuzzy(df_raw, ["æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"])
        inv_buy_asset = find_row_fuzzy(df_raw, ["è´­å»ºå›ºå®šèµ„äº§ã€æ— å½¢èµ„äº§å’Œå…¶ä»–é•¿æœŸèµ„äº§æ”¯ä»˜çš„ç°é‡‘"])
        fin_net = find_row_fuzzy(df_raw, ["ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"])
        fin_in_total = find_row_fuzzy(df_raw, ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥å°è®¡"])
        fin_borrow_in = find_row_fuzzy(df_raw, ["å–å¾—å€Ÿæ¬¾æ”¶åˆ°çš„ç°é‡‘"])
        fin_invest_in = find_row_fuzzy(df_raw, ["å¸æ”¶æŠ•èµ„æ”¶åˆ°çš„ç°é‡‘"])
        fin_out_total = find_row_fuzzy(df_raw, ["ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºå°è®¡"])
        fin_repay = find_row_fuzzy(df_raw, ["å¿è¿˜å€ºåŠ¡æ”¯ä»˜çš„ç°é‡‘"])
        fin_interest = find_row_fuzzy(df_raw, ["åˆ†é…è‚¡åˆ©ã€åˆ©æ¶¦æˆ–å¿ä»˜åˆ©æ¯æ”¯ä»˜çš„ç°é‡‘"])

        # ğŸŸ¢ [ä¿®æ”¹]ï¼šæ”¹ç”¨ container + markdown + code
        with st.container(border=True):
            st.markdown("#### ğŸ“ 1ã€ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡åˆ†æ")
            text_op = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººç»è¥æ´»åŠ¨ç°é‡‘æµå…¥åˆ†åˆ«ä¸º{op_in_total['T_2']:,.2f}ä¸‡å…ƒã€{op_in_total['T_1']:,.2f}ä¸‡å…ƒå’Œ{op_in_total['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                     f"å…¶ä¸­ï¼Œé”€å”®å•†å“ã€æä¾›åŠ³åŠ¡æ”¶åˆ°çš„ç°é‡‘åˆ†åˆ«ä¸º{op_sales['T_2']:,.2f}ä¸‡å…ƒã€{op_sales['T_1']:,.2f}ä¸‡å…ƒåŠ{op_sales['T']:,.2f}ä¸‡å…ƒï¼Œ"
                     f"å ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥çš„{safe_pct(op_sales['T_2'], op_in_total['T_2']):.2f}%ã€{safe_pct(op_sales['T_1'], op_in_total['T_1']):.2f}%åŠ{safe_pct(op_sales['T'], op_in_total['T']):.2f}%ï¼›\n\n"
                     f"æ”¶åˆ°å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘åˆ†åˆ«ä¸º{op_other_in['T_2']:,.2f}ä¸‡å…ƒã€{op_other_in['T_1']:,.2f}ä¸‡å…ƒåŠ{op_other_in['T']:,.2f}ä¸‡å…ƒï¼Œ"
                     f"å ç»è¥æ´»åŠ¨ç°é‡‘æµå…¥çš„{safe_pct(op_other_in['T_2'], op_in_total['T_2']):.2f}%ã€{safe_pct(op_other_in['T_1'], op_in_total['T_1']):.2f}%åŠ{safe_pct(op_other_in['T'], op_in_total['T']):.2f}%ã€‚"
                     f"å‘è¡Œäººæ”¶åˆ°å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘ä¸»è¦åŒ…æ‹¬ã€ã€‘ã€‚\n\n")
            text_op += (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºåˆ†åˆ«ä¸º{op_out_total['T_2']:,.2f}ä¸‡å…ƒã€{op_out_total['T_1']:,.2f}ä¸‡å…ƒå’Œ{op_out_total['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                      f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºä¸»è¦æ¥æºäºã€ã€‘ã€‚"
                      f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººè´­ä¹°å•†å“ã€æ¥å—åŠ³åŠ¡æ”¯ä»˜çš„ç°é‡‘åˆ†åˆ«ä¸º{op_buy['T_2']:,.2f}ä¸‡å…ƒã€{op_buy['T_1']:,.2f}ä¸‡å…ƒåŠ{op_buy['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"å ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºçš„{safe_pct(op_buy['T_2'], op_out_total['T_2']):.2f}%ã€{safe_pct(op_buy['T_1'], op_out_total['T_1']):.2f}%åŠ{safe_pct(op_buy['T'], op_out_total['T']):.2f}%ã€‚\n\n"
                      f"å‘è¡Œäººæ”¯ä»˜å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘åˆ†åˆ«ä¸º{op_other_out['T_2']:,.2f}ä¸‡å…ƒã€{op_other_out['T_1']:,.2f}ä¸‡å…ƒåŠ{op_other_out['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"å ç»è¥æ´»åŠ¨ç°é‡‘æµå‡ºçš„{safe_pct(op_other_out['T_2'], op_out_total['T_2']):.2f}%ã€{safe_pct(op_other_out['T_1'], op_out_total['T_1']):.2f}%åŠ{safe_pct(op_other_out['T'], op_out_total['T']):.2f}%ã€‚"
                      f"æ”¯ä»˜å…¶ä»–ä¸ç»è¥æ´»åŠ¨æœ‰å…³çš„ç°é‡‘åŒ…æ‹¬ï¼šã€ã€‘ã€‚\n\n")
            text_op += (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢åˆ†åˆ«ä¸º{op_net['T_2']:,.2f}ä¸‡å…ƒã€{op_net['T_1']:,.2f}ä¸‡å…ƒå’Œ{op_net['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"ä¸»è¦ç³»ã€ã€‘æ‰€è‡´ã€‚")
            st.markdown(text_op)
            st.code(text_op, language='text')

        with st.container(border=True):
            st.markdown("#### ğŸ“ 2ã€æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡åˆ†æ")
            text_inv = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡ŒäººæŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢åˆ†åˆ«ä¸º{inv_net['T_2']:,.2f}ä¸‡å…ƒã€{inv_net['T_1']:,.2f}ä¸‡å…ƒå’Œ{inv_net['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                      f"æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå…¥åˆ†åˆ«ä¸º{inv_in_total['T_2']:,.2f}ä¸‡å…ƒã€{inv_in_total['T_1']:,.2f}ä¸‡å…ƒåŠ{inv_in_total['T']:,.2f}ä¸‡å…ƒï¼›"
                      f"æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºåˆ†åˆ«ä¸º{inv_out_total['T_2']:,.2f}ä¸‡å…ƒã€{inv_out_total['T_1']:,.2f}ä¸‡å…ƒåŠ{inv_out_total['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"å…¶ä¸­è´­å»ºå›ºå®šèµ„äº§ã€æ— å½¢èµ„äº§å’Œå…¶ä»–é•¿æœŸèµ„äº§æ”¯ä»˜çš„ç°é‡‘åˆ†åˆ«ä¸º{inv_buy_asset['T_2']:,.2f}ä¸‡å…ƒã€{inv_buy_asset['T_1']:,.2f}ä¸‡å…ƒåŠ{inv_buy_asset['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"å æŠ•èµ„æ´»åŠ¨ç°é‡‘æµå‡ºçš„{safe_pct(inv_buy_asset['T_2'], inv_out_total['T_2']):.2f}%ã€{safe_pct(inv_buy_asset['T_1'], inv_out_total['T_1']):.2f}%åŠ{safe_pct(inv_buy_asset['T'], inv_out_total['T']):.2f}%ã€‚\n\n"
                      f"å‘è¡ŒäººæŠ•èµ„æ´»åŠ¨ç°é‡‘æµé‡å‡€é¢ã€ã€‘ï¼Œä¸»è¦æ˜¯å‘è¡Œäººã€ã€‘æ‰€è‡´ã€‚")
            st.markdown(text_inv)
            st.code(text_inv, language='text')

        with st.container(border=True):
            st.markdown("#### ğŸ“ 3ã€ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡åˆ†æ")
            text_fin = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢åˆ†åˆ«ä¸º{fin_net['T_2']:,.2f}ä¸‡å…ƒã€{fin_net['T_1']:,.2f}ä¸‡å…ƒå’Œ{fin_net['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                      f"æŠ¥å‘ŠæœŸå†…ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢ã€ã€‘ï¼Œä¸»è¦ç³»ã€ã€‘æ‰€è‡´ã€‚\n\n")
            text_fin += (f"ç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥æ–¹é¢ï¼Œå‘è¡Œäººç­¹èµ„æ´»åŠ¨ç°é‡‘æµå…¥ä¸»è¦ç”±ã€ã€‘æ„æˆã€‚"
                       f"{d_t2}ã€{d_t1}åŠ{d_t}ï¼Œå‘è¡Œäººç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµå…¥åˆ†åˆ«ä¸º{fin_in_total['T_2']:,.2f}ä¸‡å…ƒã€{fin_in_total['T_1']:,.2f}ä¸‡å…ƒåŠ{fin_in_total['T']:,.2f}ä¸‡å…ƒï¼Œ"
                       f"å…¶ä¸­å–å¾—å€Ÿæ¬¾æ”¶åˆ°çš„ç°é‡‘åˆ†åˆ«ä¸º{fin_borrow_in['T_2']:,.2f}ä¸‡å…ƒã€{fin_borrow_in['T_1']:,.2f}ä¸‡å…ƒåŠ{fin_borrow_in['T']:,.2f}ä¸‡å…ƒï¼›"
                       f"å¸æ”¶æŠ•èµ„æ”¶åˆ°çš„ç°é‡‘åˆ†åˆ«ä¸º{fin_invest_in['T_2']:,.2f}ä¸‡å…ƒã€{fin_invest_in['T_1']:,.2f}ä¸‡å…ƒåŠ{fin_invest_in['T']:,.2f}ä¸‡å…ƒã€‚\n\n")
            text_fin += (f"{d_t2}ã€{d_t1}åŠ{d_t}ï¼Œå‘è¡Œäººç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµå‡ºåˆ†åˆ«ä¸º{fin_out_total['T_2']:,.2f}ä¸‡å…ƒã€{fin_out_total['T_1']:,.2f}ä¸‡å…ƒå’Œ{fin_out_total['T']:,.2f}ä¸‡å…ƒã€‚"
                       f"å‘è¡Œäººç­¹èµ„æ´»åŠ¨ç°é‡‘æµå‡ºä¸»è¦ç”±ã€ã€‘æ„æˆã€‚"
                       f"å…¶ä¸­æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººå¿è¿˜å€ºåŠ¡æ”¯ä»˜çš„ç°é‡‘åˆ†åˆ«ä¸º{fin_repay['T_2']:,.2f}ä¸‡å…ƒã€{fin_repay['T_1']:,.2f}ä¸‡å…ƒå’Œ{fin_repay['T']:,.2f}ä¸‡å…ƒï¼Œ"
                       f"åˆ†é…è‚¡åˆ©ã€åˆ©æ¶¦æˆ–å¿ä»˜åˆ©æ¯æ‰€æ”¯ä»˜çš„ç°é‡‘åˆ†åˆ«ä¸º{fin_interest['T_2']:,.2f}ä¸‡å…ƒã€{fin_interest['T_1']:,.2f}ä¸‡å…ƒå’Œ{fin_interest['T']:,.2f}ä¸‡å…ƒã€‚")
            st.markdown(text_fin)
            st.code(text_fin, language='text')

    with tab4:
        st.info("ğŸ’¡ **æç¤º**ï¼šå·²è‡ªåŠ¨ç”Ÿæˆå‡€ç°é‡‘æµé‡å˜åŠ¨åˆ†ææ–‡æ¡ˆè‰ç¨¿ã€‚")
        target_subjects = ["ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢", "æŠ•èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢", "ç­¹èµ„æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"]
        for subject in target_subjects:
            row = find_row_fuzzy(df_raw, [subject])
            if row.name is None: continue
            diff_prev = row['T_1'] - row['T_2']
            diff_curr = row['T'] - row['T_1']
            dir_prev = "å¢åŠ " if diff_prev >= 0 else "å‡å°‘"
            dir_curr = "å¢åŠ " if diff_curr >= 0 else "å‡å°‘"
            
            # ç”Ÿæˆå˜åŠ¨åˆ†ææ–‡æ¡ˆ
            cf_text = (f"æŠ¥å‘ŠæœŸå„æœŸï¼Œå‘è¡Œäºº{subject}åˆ†åˆ«ä¸º{row['T_2']:,.2f}ä¸‡å…ƒã€{row['T_1']:,.2f}ä¸‡å…ƒå’Œ{row['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                     f"{d_t1}ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_t2}å‡€{dir_prev}{abs(diff_prev):,.2f}ä¸‡å…ƒï¼›\n"
                     f"{d_t}ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_t1}å‡€{dir_curr}{abs(diff_curr):,.2f}ä¸‡å…ƒã€‚\n\n"
                     f"å˜åŠ¨ä¸»è¦åŸå› ä¸ºï¼šï¼ˆè¯·åœ¨æ­¤å¤„è¡¥å……å…·ä½“çš„ä¸šåŠ¡æˆ–èµ„é‡‘å˜åŠ¨åŸå› ï¼‰ã€‚")
            
            # ğŸŸ¢ [ä¿®æ”¹]ï¼šExpanderå†…ç›´æ¥å±•ç¤º markdown + ä»£ç æ¡†
            with st.expander(f"ğŸ“Œ {subject}"):
                st.markdown(cf_text)
                st.code(cf_text, language='text')

# ================= 5. ä¸šåŠ¡é€»è¾‘ï¼šç›ˆåˆ©èƒ½åŠ›åˆ†æ (NEW!) =================
def process_profitability_tab(df_raw, word_data_list, d_labels):
    d_t, d_t1, d_t2 = d_labels
    
    # 1. å®šä¹‰æ ‡å‡†åŒ–çš„ç§‘ç›®åç§°é¡ºåº
    standard_items = [
        "è¥ä¸šæ”¶å…¥", "è¥ä¸šæˆæœ¬", "é”€å”®è´¹ç”¨", "ç®¡ç†è´¹ç”¨", "ç ”å‘è´¹ç”¨", "è´¢åŠ¡è´¹ç”¨",
        "å…¶ä»–æ”¶ç›Š", "è¥ä¸šåˆ©æ¶¦", "è¥ä¸šå¤–æ”¶å…¥", "è¥ä¸šå¤–æ”¯å‡º", "åˆ©æ¶¦æ€»é¢", "å‡€åˆ©æ¶¦",
        "è¥ä¸šæ¯›åˆ©ç‡", "å¹³å‡æ€»èµ„äº§å›æŠ¥ç‡"
    ]

    # 2. æŸ¥æ‰¾å…³é”®æ•°æ®è¡Œ (ä½¿ç”¨æ›´çµæ´»çš„æ¨¡ç³ŠåŒ¹é…)
    def get_row_data(keywords, default_zero=True):
        row = find_row_fuzzy(df_raw, keywords)
        if row.name:
            return row['T'], row['T_1'], row['T_2']
        return 0, 0, 0 if default_zero else (None, None, None)

    # æå–åŸºç¡€æ•°æ®ç”¨äºåç»­è®¡ç®—
    rev_t, rev_t1, rev_t2 = get_row_data(['è¥ä¸šæ”¶å…¥'])
    cost_t, cost_t1, cost_t2 = get_row_data(['è¥ä¸šæˆæœ¬'])

    # æ„å»ºè¡¨æ ¼æ•°æ®åˆ—è¡¨
    data_list = []
    
    for item in standard_items:
        # ç‰¹æ®Šè®¡ç®—è¡Œ
        if item == "è¥ä¸šæ¯›åˆ©ç‡":
            m_t = (rev_t - cost_t) / rev_t * 100 if rev_t != 0 else 0.0
            m_t1 = (rev_t1 - cost_t1) / rev_t1 * 100 if rev_t1 != 0 else 0.0
            m_t2 = (rev_t2 - cost_t2) / rev_t2 * 100 if rev_t2 != 0 else 0.0
            data_list.append([item, f"{m_t:.2f}", f"{m_t1:.2f}", f"{m_t2:.2f}"])
        elif item == "å¹³å‡æ€»èµ„äº§å›æŠ¥ç‡":
            # æš‚æ— æ•°æ®ï¼Œç•™ç©º
            data_list.append([item, "", "", ""])
        else:
            # å¸¸è§„ç§‘ç›®æŸ¥æ‰¾
            # é’ˆå¯¹ä¸€äº›ç§‘ç›®å®šä¹‰åˆ«ååˆ—è¡¨ä»¥æé«˜å‘½ä¸­ç‡
            search_kws = [item]
            if item == "è¥ä¸šåˆ©æ¶¦": search_kws = ['è¥ä¸šåˆ©æ¶¦', 'ä¸‰ã€è¥ä¸šåˆ©æ¶¦']
            elif item == "åˆ©æ¶¦æ€»é¢": search_kws = ['åˆ©æ¶¦æ€»é¢', 'å››ã€åˆ©æ¶¦æ€»é¢']
            elif item == "å‡€åˆ©æ¶¦": search_kws = ['å‡€åˆ©æ¶¦', 'äº”ã€å‡€åˆ©æ¶¦']
            elif item == "ç ”å‘è´¹ç”¨": search_kws = ['ç ”å‘è´¹ç”¨'] # ç¡®ä¿èƒ½æ‰¾åˆ°ç ”å‘
            
            val_t, val_t1, val_t2 = get_row_data(search_kws)
            
            # æ ¼å¼åŒ–
            f_t = f"{val_t:,.2f}" if val_t != 0 else "0.00"
            f_t1 = f"{val_t1:,.2f}" if val_t1 != 0 else "0.00"
            f_t2 = f"{val_t2:,.2f}" if val_t2 != 0 else "0.00"
            
            # å¦‚æœæ˜¯å…¶ä»–æ”¶ç›Šä¸”ä¸º0ï¼Œå¯èƒ½æƒ³ç•™ç©ºï¼Ÿè¿™é‡Œç»Ÿä¸€æ˜¾ç¤º0.00ä¿æŒä¸€è‡´ï¼Œæˆ–è€…æ ¹æ®éœ€æ±‚æ”¹
            if item == "å…¶ä»–æ”¶ç›Š" and val_t == 0 and val_t1 == 0 and val_t2 == 0:
                 f_t, f_t1, f_t2 = "", "", ""

            data_list.append([item, f_t, f_t1, f_t2])

    # è½¬ DataFrame
    df_fmt = pd.DataFrame(data_list, columns=["é¡¹ç›®", d_t, d_t1, d_t2])
    df_fmt.set_index("é¡¹ç›®", inplace=True)

    # 4. è®¡ç®—é€»è¾‘ (ç”¨äºæ–‡æ¡ˆ) - é‡æ–°è·å–ä¸€æ¬¡ä»¥ä¾¿æ–‡æ¡ˆç”Ÿæˆä½¿ç”¨æ–¹ä¾¿
    margins = {
        'T': (rev_t - cost_t) / rev_t * 100 if rev_t != 0 else 0.0,
        'T_1': (rev_t1 - cost_t1) / rev_t1 * 100 if rev_t1 != 0 else 0.0,
        'T_2': (rev_t2 - cost_t2) / rev_t2 * 100 if rev_t2 != 0 else 0.0
    }
    
    # é‡æ–°è®¡ç®—æœŸé—´è´¹ç”¨æ€»é¢ (æ–‡æ¡ˆç”¨)
    def get_val(name):
        r = get_row_data([name])
        return {'T': r[0], 'T_1': r[1], 'T_2': r[2]}
        
    exp_items = ['é”€å”®è´¹ç”¨', 'ç®¡ç†è´¹ç”¨', 'ç ”å‘è´¹ç”¨', 'è´¢åŠ¡è´¹ç”¨']
    period_expenses = {'T': 0, 'T_1': 0, 'T_2': 0}
    for ex in exp_items:
        vals = get_val(ex)
        for k in period_expenses: period_expenses[k] += vals[k]

    pe_ratios = {}
    for col in ['T', 'T_1', 'T_2']:
        r_val = rev_t if col == 'T' else (rev_t1 if col == 'T_1' else rev_t2)
        pe_ratios[col] = period_expenses[col] / r_val * 100 if r_val != 0 else 0.0
    
    # ğŸŸ¢ [æ–°å¢]ï¼šæŸ¥æ‰¾æœŸé—´è´¹ç”¨åˆ†ææ‰€éœ€çš„æ‰€æœ‰è´¹ç”¨è¡Œ
    idx_start = find_index_fuzzy(df_raw, ['è¥ä¸šæ€»æˆæœ¬', 'äºŒã€è¥ä¸šæ€»æˆæœ¬'])
    idx_end = find_index_fuzzy(df_raw, ['èµ„äº§å‡å€¼æŸå¤±', 'åŠ ï¼šèµ„äº§å‡å€¼æŸå¤±', 'æŠ•èµ„æ”¶ç›Š'])
    
    all_expense_rows = []
    if idx_start and idx_end and idx_end > idx_start:
        subset = df_raw.iloc[idx_start+1 : idx_end]
        for i in range(len(subset)):
            row = subset.iloc[i]
            if "è´¹ç”¨" in str(row.name):
                all_expense_rows.append(row)
    else:
        # Fallback if structure not found
        for kw in exp_items:
             r = find_row_fuzzy(df_raw, [kw])
             if r.name: all_expense_rows.append(r)

    # ğŸŸ¢ [æ–°å¢]ï¼šæ„å»ºæœŸé—´è´¹ç”¨åˆ†æè¡¨æ ¼æ•°æ®
    period_exp_data = []
    for r in all_expense_rows:
        row_dat = [r.name]
        
        # T (Latest)
        val_t = r['T']
        pct_t = val_t / rev_t * 100 if rev_t else 0
        row_dat.extend([f"{val_t:,.2f}", f"{pct_t:.2f}%"])
        
        # T-1
        val_t1 = r['T_1']
        pct_t1 = val_t1 / rev_t1 * 100 if rev_t1 else 0
        row_dat.extend([f"{val_t1:,.2f}", f"{pct_t1:.2f}%"])

        # T-2
        val_t2 = r['T_2']
        pct_t2 = val_t2 / rev_t2 * 100 if rev_t2 else 0
        row_dat.extend([f"{val_t2:,.2f}", f"{pct_t2:.2f}%"])
        
        period_exp_data.append(row_dat)
    
    # ğŸŸ¢ [ä¿®å¤]ï¼šä½¿ç”¨å¸¦å¹´ä»½çš„åˆ—åï¼Œé¿å… Duplicate column names é”™è¯¯
    pe_cols = ["é¡¹ç›®", 
               f"{d_t}é‡‘é¢", f"{d_t}å æ¯”", 
               f"{d_t1}é‡‘é¢", f"{d_t1}å æ¯”",
               f"{d_t2}é‡‘é¢", f"{d_t2}å æ¯”"]
    
    df_period_exp = pd.DataFrame(period_exp_data, columns=pe_cols).set_index("é¡¹ç›®")

    # UI å±•ç¤º
    # ğŸŸ¢ [ä¿®æ”¹]ï¼šæ–°å¢ Tab 2 æœŸé—´è´¹ç”¨åˆ†æ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ç›ˆåˆ©èƒ½åŠ›æ˜ç»†", "ğŸ“Š æœŸé—´è´¹ç”¨åˆ†æ", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ“ å˜åŠ¨åˆ†ææ–‡æ¡ˆ"])

    with tab1:
        c1, c2, c3 = st.columns([6, 1.2, 1.2]) 
        with c1: st.markdown("### ç›ˆåˆ©èƒ½åŠ›æ˜ç»†è¡¨")
        with c2:
            doc_file = create_word_table_file(df_fmt, title="ç›ˆåˆ©èƒ½åŠ›åˆ†æè¡¨")
            st.download_button("ğŸ“¥ ä¸‹è½½ Word", doc_file, "ç›ˆåˆ©èƒ½åŠ›è¡¨.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file = create_excel_file(df_fmt)
            st.download_button("ğŸ“¥ ä¸‹è½½ Excel", excel_file, "ç›ˆåˆ©èƒ½åŠ›è¡¨.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(df_fmt, use_container_width=True)
    
    # ğŸŸ¢ [æ–°å¢]ï¼šæœŸé—´è´¹ç”¨åˆ†æ Tab å†…å®¹
    with tab2:
        c1, c2, c3 = st.columns([6, 1.2, 1.2])
        with c1: st.markdown("### æœŸé—´è´¹ç”¨åˆ†æè¡¨")
        with c2:
            doc_file_pe = create_word_table_file(df_period_exp, title="æœŸé—´è´¹ç”¨åˆ†æè¡¨")
            st.download_button("ğŸ“¥ ä¸‹è½½ Word", doc_file_pe, "æœŸé—´è´¹ç”¨åˆ†æè¡¨.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file_pe = create_excel_file(df_period_exp)
            st.download_button("ğŸ“¥ ä¸‹è½½ Excel", excel_file_pe, "æœŸé—´è´¹ç”¨åˆ†æè¡¨.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(df_period_exp, use_container_width=True)

    with tab3:
        # ğŸŸ¢ [ä¿®æ”¹]ï¼šæ”¹ç”¨ container + markdown + code
        with st.container(border=True):
            st.markdown("#### ğŸ“ 1ã€è¥ä¸šæ”¶å…¥ã€è¥ä¸šæˆæœ¬å’Œæ¯›åˆ©ç‡åˆ†æ")
            text_1 = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººå„æœŸçš„è¥ä¸šæ”¶å…¥åˆ†åˆ«ä¸º{rev_t2:,.2f}ä¸‡å…ƒã€{rev_t1:,.2f}ä¸‡å…ƒå’Œ{rev_t:,.2f}ä¸‡å…ƒï¼Œ"
                      f"è¥ä¸šæˆæœ¬åˆ†åˆ«ä¸º{cost_t2:,.2f}ä¸‡å…ƒã€{cost_t1:,.2f}ä¸‡å…ƒå’Œ{cost_t:,.2f}ä¸‡å…ƒï¼Œ"
                      f"è¥ä¸šæ¯›åˆ©ç‡åˆ†åˆ«ä¸º{margins['T_2']:.2f}%ã€{margins['T_1']:.2f}%å’Œ{margins['T']:.2f}%ã€‚\n\n"
                      f"å‘è¡Œäººä»¥ï¼ˆï¼‰ä¸ºä¸»è¦ä¸šåŠ¡ï¼Œä¸»è¦ä¸šåŠ¡æ¯›åˆ©æ°´å¹³è¾ƒç¨³å®šã€‚")
            st.markdown(text_1)
            st.code(text_1, language='text')

        with st.container(border=True):
            st.markdown("#### ğŸ“ 2ã€æœŸé—´è´¹ç”¨åˆ†æ")
            text_2 = (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡ŒäººæœŸé—´è´¹ç”¨æ€»é¢åˆ†åˆ«ä¸º{period_expenses['T_2']:,.2f}ä¸‡å…ƒã€{period_expenses['T_1']:,.2f}ä¸‡å…ƒå’Œ{period_expenses['T']:,.2f}ä¸‡å…ƒï¼Œ"
                      f"å å‘è¡Œäººè¥ä¸šæ”¶å…¥çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{pe_ratios['T_2']:.2f}%ã€{pe_ratios['T_1']:.2f}%å’Œ{pe_ratios['T']:.2f}%ã€‚\n\n"
                      f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡ŒäººæœŸé—´è´¹ç”¨ä¸»è¦ä¸ºé”€å”®è´¹ç”¨ã€ç®¡ç†è´¹ç”¨ã€ç ”å‘è´¹ç”¨å’Œè´¢åŠ¡è´¹ç”¨ï¼Œæœ€è¿‘ä¸¤å¹´å‘è¡ŒäººæœŸé—´è´¹ç”¨è¾ƒä¸ºç¨³å®šã€‚\n\n")
            
            # åˆ†é¡¹åˆ†æ
            for name in exp_items:
                vals = get_val(name)
                # å æœŸé—´è´¹ç”¨æ¯”ä¾‹
                pct_pe_t = safe_pct(vals['T'], period_expenses['T'])
                pct_pe_t1 = safe_pct(vals['T_1'], period_expenses['T_1'])
                pct_pe_t2 = safe_pct(vals['T_2'], period_expenses['T_2'])
                # å è¥æ”¶æ¯”ä¾‹
                pct_rev_t = safe_pct(vals['T'], rev_t)
                pct_rev_t1 = safe_pct(vals['T_1'], rev_t1)
                pct_rev_t2 = safe_pct(vals['T_2'], rev_t2)
                
                text_2 += (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººå‘ç”Ÿ{name}åˆ†åˆ«ä¸º{vals['T_2']:,.2f}ä¸‡å…ƒã€{vals['T_1']:,.2f}ä¸‡å…ƒå’Œ{vals['T']:,.2f}ä¸‡å…ƒï¼Œ"
                           f"å æœŸé—´è´¹ç”¨çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{pct_pe_t2:.2f}%ã€{pct_pe_t1:.2f}%å’Œ{pct_pe_t:.2f}%ï¼Œ"
                           f"å è¥ä¸šæ”¶å…¥çš„æ¯”é‡åˆ†åˆ«ä¸º{pct_rev_t2:.2f}%ã€{pct_rev_t1:.2f}%å’Œ{pct_rev_t:.2f}%ã€‚\n\n")
            
            st.markdown(text_2)
            st.code(text_2, language='text')

    with tab4:
        st.info("ğŸ’¡ **æç¤º**ï¼šå·²è‡ªåŠ¨ç”Ÿæˆå…³é”®ç›ˆåˆ©æŒ‡æ ‡å˜åŠ¨åˆ†ææ–‡æ¡ˆè‰ç¨¿ã€‚")
        # 1. æ”¶å…¥åˆ†æ
        diff_rev_prev = rev_t1 - rev_t2
        diff_rev_curr = rev_t - rev_t1
        rev_text = (f"æŠ¥å‘ŠæœŸå„æœŸï¼Œå‘è¡Œäººè¥ä¸šæ”¶å…¥åˆ†åˆ«ä¸º{rev_t2:,.2f}ä¸‡å…ƒã€{rev_t1:,.2f}ä¸‡å…ƒå’Œ{rev_t:,.2f}ä¸‡å…ƒã€‚\n"
                    f"{d_t1}è¥ä¸šæ”¶å…¥è¾ƒ{d_t2}å˜åŠ¨{diff_rev_prev:,.2f}ä¸‡å…ƒï¼›\n"
                    f"{d_t}è¥ä¸šæ”¶å…¥è¾ƒ{d_t1}å˜åŠ¨{diff_rev_curr:,.2f}ä¸‡å…ƒã€‚\n"
                    f"å˜åŠ¨ä¸»è¦åŸå› ä¸ºï¼šï¼ˆè¯·ç»“åˆä¸šåŠ¡è§„æ¨¡ã€è®¢å•é‡ã€å•ä»·ç­‰å› ç´ åˆ†æï¼‰ã€‚")
        # ğŸŸ¢ [ä¿®æ”¹]ï¼šExpanderå†…æ”¹ç”¨ markdown + code
        with st.expander("ğŸ“Œ è¥ä¸šæ”¶å…¥"): 
            st.markdown(rev_text)
            st.code(rev_text, language='text')
        
        # 2. æ¯›åˆ©ç‡åˆ†æ
        margin_text = (f"æŠ¥å‘ŠæœŸå„æœŸï¼Œå‘è¡Œäººæ¯›åˆ©ç‡åˆ†åˆ«ä¸º{margins['T_2']:.2f}%ã€{margins['T_1']:.2f}%ã€{margins['T']:.2f}%ã€‚\n"
                       f"å‘è¡Œäººæ¯›åˆ©ç‡å˜åŠ¨ä¸»è¦ç³»ï¼šï¼ˆè¯·ç»“åˆæˆæœ¬æ³¢åŠ¨ã€äº§å“å®šä»·ç­–ç•¥ç­‰å› ç´ åˆ†æï¼‰ã€‚")
        with st.expander("ğŸ“Œ æ¯›åˆ©ç‡"): 
            st.markdown(margin_text)
            st.code(margin_text, language='text')

        # 3. å‡€åˆ©æ¶¦åˆ†æ
        net_t, net_t1, net_t2 = get_row_data(['å‡€åˆ©æ¶¦', 'äº”ã€å‡€åˆ©æ¶¦'])
        net_text = (f"æŠ¥å‘ŠæœŸå„æœŸï¼Œå‘è¡Œäººå‡€åˆ©æ¶¦åˆ†åˆ«ä¸º{net_t2:,.2f}ä¸‡å…ƒã€{net_t1:,.2f}ä¸‡å…ƒå’Œ{net_t:,.2f}ä¸‡å…ƒã€‚\n"
                    f"å‡€åˆ©æ¶¦å˜åŠ¨è¶‹åŠ¿ä¸åˆ©æ¶¦æ€»é¢å˜åŠ¨è¶‹åŠ¿ä¸€è‡´ï¼Œå˜åŠ¨åŸå› ä¸»è¦ä¸ºï¼šï¼ˆè¯·è¡¥å……éç»å¸¸æ€§æŸç›Šæˆ–ç¨åŠ¡å½±å“ç­‰åŸå› ï¼‰ã€‚")
        with st.expander("ğŸ“Œ å‡€åˆ©æ¶¦"): 
            st.markdown(net_text)
            st.code(net_text, language='text')


# ================= 5. ä¸šåŠ¡é€»è¾‘ï¼šè´¢åŠ¡æŒ‡æ ‡åˆ†æ =================
def process_financial_ratios_tab(df_raw, word_data_list, d_labels):
    d_t, d_t1, d_t2 = d_labels
    
    # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼š(æ˜¾ç¤ºåç§°, [æœç´¢å…³é”®è¯], [æ’é™¤å…³é”®è¯])
    metrics_config = [
        ("èµ„äº§è´Ÿå€ºç‡ï¼ˆ%ï¼‰", ["èµ„äº§è´Ÿå€ºç‡"], ["å¹³å‡"]), # æ’é™¤â€œå¹³å‡èµ„äº§è´Ÿå€ºç‡â€
        ("æµåŠ¨æ¯”ç‡ï¼ˆå€ï¼‰", ["æµåŠ¨æ¯”ç‡"], None),
        ("é€ŸåŠ¨æ¯”ç‡ï¼ˆå€ï¼‰", ["é€ŸåŠ¨æ¯”ç‡"], None),
        ("EBITDAï¼ˆä¸‡å…ƒï¼‰", ["EBITDA", "æ¯ç¨æŠ˜æ—§æ‘Šé”€å‰åˆ©æ¶¦"], ["å€", "æ¯”", "ç‡", "/", "%", "å…¨éƒ¨å€ºåŠ¡", "åˆ©æ¯"]), # æ’é™¤æ¯”ç‡ç±»
        ("EBITDAåˆ©æ¯ä¿éšœå€æ•°ï¼ˆå€ï¼‰", ["EBITDAåˆ©æ¯ä¿éšœå€æ•°", "åˆ©æ¯ä¿éšœå€æ•°", "EBITDAåˆ©æ¯å€æ•°"], None)
    ]
    
    data_list = []
    data_map = {} 
    
    for display_name, search_kws, ex_kws in metrics_config:
        # ä½¿ç”¨ä¸å¸¦å•ä½çš„å…³é”®è¯å»æ¨¡ç³Šæœç´¢
        row = find_row_fuzzy(df_raw, search_kws, exclude_keywords=ex_kws)
        
        val_t, val_t1, val_t2 = 0, 0, 0
        if row.name is not None:
            # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šåº”ç”¨æ™ºèƒ½å•ä½è½¬æ¢
            is_ebitda = "EBITDAï¼ˆä¸‡å…ƒï¼‰" in display_name
            is_ratio = "èµ„äº§è´Ÿå€ºç‡" in display_name
            
            # ä¼ å…¥ subject_name å¸®åŠ©åˆ¤æ–­å•ä½
            val_t = smart_scale_convert(row['T'], row.name, is_ebitda, is_ratio)
            val_t1 = smart_scale_convert(row['T_1'], row.name, is_ebitda, is_ratio)
            val_t2 = smart_scale_convert(row['T_2'], row.name, is_ebitda, is_ratio)
            
            data_map[display_name] = {'T': val_t, 'T_1': val_t1, 'T_2': val_t2}
        
        if "EBITDAï¼ˆä¸‡å…ƒï¼‰" in display_name:
            fmt_t = f"{val_t:,.2f}"
            fmt_t1 = f"{val_t1:,.2f}"
            fmt_t2 = f"{val_t2:,.2f}"
        else:
            fmt_t = f"{val_t:.2f}"
            fmt_t1 = f"{val_t1:.2f}"
            fmt_t2 = f"{val_t2:.2f}"
            
        data_list.append([display_name, fmt_t, fmt_t1, fmt_t2])

    df_display = pd.DataFrame(data_list, columns=["é¡¹ç›®", d_t, d_t1, d_t2])
    df_display.set_index("é¡¹ç›®", inplace=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ æŒ‡æ ‡æ•°æ®", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ“ å˜åŠ¨åˆ†ææ–‡æ¡ˆ"])

    with tab1:
        c1, c2, c3 = st.columns([6, 1.2, 1.2]) 
        with c1: st.markdown("### ä¸»è¦å¿å€ºæŒ‡æ ‡")
        with c2:
            doc_file = create_word_table_file(df_display, title="ä¸»è¦è´¢åŠ¡æŒ‡æ ‡è¡¨")
            st.download_button("ğŸ“¥ ä¸‹è½½ Word", doc_file, "è´¢åŠ¡æŒ‡æ ‡è¡¨.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file = create_excel_file(df_display)
            st.download_button("ğŸ“¥ ä¸‹è½½ Excel", excel_file, "è´¢åŠ¡æŒ‡æ ‡è¡¨.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.dataframe(df_display, use_container_width=True)

    with tab2:
        alr = data_map.get("èµ„äº§è´Ÿå€ºç‡ï¼ˆ%ï¼‰", {'T':0,'T_1':0,'T_2':0})
        cr = data_map.get("æµåŠ¨æ¯”ç‡ï¼ˆå€ï¼‰", {'T':0,'T_1':0,'T_2':0})
        qr = data_map.get("é€ŸåŠ¨æ¯”ç‡ï¼ˆå€ï¼‰", {'T':0,'T_1':0,'T_2':0})
        ebitda = data_map.get("EBITDAï¼ˆä¸‡å…ƒï¼‰", {'T':0,'T_1':0,'T_2':0})
        int_cov = data_map.get("EBITDAåˆ©æ¯ä¿éšœå€æ•°ï¼ˆå€ï¼‰", {'T':0,'T_1':0,'T_2':0})

        # ğŸŸ¢ [ä¿®æ”¹]ï¼šæ”¹ç”¨ container + markdown + code
        with st.container(border=True):
            st.markdown("#### ğŸ“ å¿å€ºèƒ½åŠ›åˆ†æç»¼è¿°")
            
            text = f"1ã€èµ„äº§è´Ÿå€ºç‡\n\n"
            text += f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººçš„èµ„äº§è´Ÿå€ºç‡åˆ†åˆ«ä¸º{alr['T_2']:.2f}%ã€{alr['T_1']:.2f}%å’Œ{alr['T']:.2f}%ã€‚\n\n"
            
            text += f"2ã€æµåŠ¨æ¯”ç‡åŠé€ŸåŠ¨æ¯”ç‡\n\n"
            text += (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººçš„æµåŠ¨æ¯”ç‡åˆ†åˆ«ä¸º{cr['T_2']:.2f}å€ã€{cr['T_1']:.2f}å€å’Œ{cr['T']:.2f}å€ï¼›"
                     f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººçš„é€ŸåŠ¨æ¯”ç‡åˆ†åˆ«ä¸º{qr['T_2']:.2f}å€ã€{qr['T_1']:.2f}å€å’Œ{qr['T']:.2f}å€ã€‚\n\n")
            
            text += f"3ã€EBITDAåˆ©æ¯ä¿éšœå€æ•°\n\n"
            text += (f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡ŒäººEBITDAåˆ†åˆ«ä¸º{ebitda['T_2']:,.2f}ä¸‡å…ƒã€{ebitda['T_1']:,.2f}ä¸‡å…ƒå’Œ{ebitda['T']:,.2f}ä¸‡å…ƒï¼Œ"
                     f"å‘è¡ŒäººEBITDAåˆ©æ¯ä¿éšœå€æ•°åˆ†åˆ«ä¸º{int_cov['T_2']:.2f}å€ã€{int_cov['T_1']:.2f}å€å’Œ{int_cov['T']:.2f}å€ã€‚")
            
            st.markdown(text)
            st.code(text, language='text')

    with tab3:
        st.info("ğŸ’¡ **æç¤º**ï¼šå·²è‡ªåŠ¨ç”Ÿæˆå…³é”®æŒ‡æ ‡å˜åŠ¨åˆ†ææ–‡æ¡ˆè‰ç¨¿ã€‚")
        prompts = [
            ("èµ„äº§è´Ÿå€ºç‡", alr, "åˆ†æå¿å€ºé£é™©å˜åŒ–"),
            ("æµåŠ¨æ¯”ç‡", cr, "åˆ†æçŸ­æœŸå¿å€ºèƒ½åŠ›"),
            ("EBITDA", ebitda, "åˆ†æç›ˆåˆ©åŠè·ç°èƒ½åŠ›")
        ]
        for name, data, task in prompts:
            # æ ¹æ®è¶‹åŠ¿åˆ¤æ–­æè¿°
            trend_text = ""
            if data['T'] > data['T_1']: trend_text = "æœ‰æ‰€ä¸Šå‡"
            elif data['T'] < data['T_1']: trend_text = "æœ‰æ‰€ä¸‹é™"
            else: trend_text = "ä¿æŒç¨³å®š"
            
            analysis_text = (f"æŠ¥å‘ŠæœŸå„æœŸï¼Œå‘è¡Œäºº{name}åˆ†åˆ«ä¸º{data['T_2']:.2f}ã€{data['T_1']:.2f}å’Œ{data['T']:.2f}ã€‚\n"
                           f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäºº{name}{trend_text}ï¼Œä¸»è¦ç³»ï¼šï¼ˆè¯·ç»“åˆèµ„äº§è´Ÿå€ºç»“æ„æˆ–ç›ˆåˆ©èƒ½åŠ›åˆ†æï¼‰ã€‚")
            
            # ğŸŸ¢ [ä¿®æ”¹]ï¼šExpanderå†…æ”¹ç”¨ markdown + code
            with st.expander(f"ğŸ“Œ {name}"):
                st.markdown(analysis_text)
                st.code(analysis_text, language='text')

# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.title("ğŸ›ï¸ æ“æ§å°")
    analysis_page = st.radio(
        "è¯·é€‰æ‹©è¦ç”Ÿæˆçš„ç« èŠ‚ï¼š", 
        ["(ä¸€) èµ„äº§ç»“æ„åˆ†æ", "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ", "(ä¸‰) ç°é‡‘æµé‡åˆ†æ", "(å››) è´¢åŠ¡æŒ‡æ ‡åˆ†æ", "(äº”) ç›ˆåˆ©èƒ½åŠ›åˆ†æ"]
    )
    st.markdown("---")
    
    uploaded_excel = st.file_uploader("Excel åº•ç¨¿ (å¿…é¡»)", type=["xlsx", "xlsm"])
    
    # ğŸ’¡ æç¤ºï¼šWord é™„æ³¨å’Œé«˜çº§è®¾ç½®å·²éšè—ï¼Œç³»ç»Ÿå°†ä½¿ç”¨é»˜è®¤é…ç½®

# ================= 4. ä¸»ç¨‹åº =================

# --- âš™ï¸ ç³»ç»Ÿé»˜è®¤é…ç½® (åŸé«˜çº§è®¾ç½®å†…å®¹) ---
# ç”±äºåˆ é™¤äº†å‰ç«¯è®¾ç½®å…¥å£ï¼Œæ­¤å¤„å®šä¹‰é»˜è®¤å€¼
DEFAULT_HEADER_ROW = 2  # ç¬¬3è¡Œ
SHEET_CONFIG = {
    "asset": "1.åˆå¹¶èµ„äº§è¡¨",
    "liab": "2.åˆå¹¶è´Ÿå€ºåŠæƒç›Šè¡¨",
    "profit": "3.åˆå¹¶åˆ©æ¶¦è¡¨",
    "cash": "4.åˆå¹¶ç°é‡‘æµé‡è¡¨",
    "ratios": "5-3ä¸»è¦è´¢åŠ¡æŒ‡æ ‡è®¡ç®—-æ–¹æ¡ˆ3ï¼ˆä¸“ç”¨å…¬å¸å€ºï¼‰"
}
# ------------------------------------

if not uploaded_excel:
    st.title("ğŸ“Š è´¢åŠ¡åˆ†ææŠ¥å‘Šè‡ªåŠ¨åŒ–åŠ©æ‰‹")
    st.info("ğŸ’¡ æœ¬ç³»ç»Ÿä¸“ä¸º **å…¬å¸æ ‡å‡†å®¡è®¡åº•ç¨¿æ¨¡ç‰ˆ** è®¾è®¡ï¼Œè¯·å‹¿éšæ„ä¿®æ”¹ Excel æ ¼å¼ã€‚")
    st.markdown("""
    ### ğŸ›‘ ä½¿ç”¨å‰å¿…è¯» (Requirements)
    ä¸ºäº†ç¡®ä¿æ•°æ®è¯»å–å‡†ç¡®ï¼Œæ‚¨çš„ Excel æ–‡ä»¶ **å¿…é¡»** æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š
    1.  **Sheet åç§°ä¸¥æ ¼åŒ¹é…**ï¼š
        * èµ„äº§è¡¨ -> `1.åˆå¹¶èµ„äº§è¡¨`
        * è´Ÿå€ºè¡¨ -> `2.åˆå¹¶è´Ÿå€ºåŠæƒç›Šè¡¨`
        * ç°é‡‘æµ -> `4.åˆå¹¶ç°é‡‘æµé‡è¡¨`
    2.  **æ•°æ®åˆ—ä½ç½®å›ºå®š**ï¼šç³»ç»Ÿé»˜è®¤è¯»å– **Eã€Fã€G åˆ—**ï¼ˆæ¨¡ç‰ˆä¸­çš„â€œä¸‡å…ƒâ€åˆ—ï¼‰ã€‚
    3.  **è¡¨å¤´ä½ç½®å›ºå®š**ï¼šè¡¨å¤´å¿…é¡»ä½äº **ç¬¬ 3 è¡Œ**ï¼ˆå³ Excel å·¦ä¾§è¡Œå·ä¸º 3ï¼‰ã€‚

    > **ğŸ’¡ å°æŠ€å·§ï¼šå¦‚ä½•è‡ªå®šä¹‰æ—¥æœŸåç§°ï¼Ÿ**
    > ç³»ç»Ÿä¼šè‡ªåŠ¨æå– Excel è¡¨å¤´ä¸­ **ã€ ã€‘** é‡Œçš„æ–‡å­—ã€‚
    > * å¦‚æœæ‚¨å¸Œæœ›æ–‡æ¡ˆæ˜¾ç¤º **â€œ2023å¹´æœ«â€**ï¼Œè¯·ç›´æ¥å°† Excel è¡¨å¤´æ”¹ä¸º `ã€2023å¹´æœ«ã€‘`ã€‚
    > * å¦‚æœæ‚¨å¸Œæœ›æ–‡æ¡ˆæ˜¾ç¤º **â€œ2025å¹´9æœˆæœ«â€**ï¼Œè¯·å°† Excel è¡¨å¤´æ”¹ä¸º `ã€2025å¹´9æœˆæœ«ã€‘`ã€‚

    ---
    ### ğŸš€ å¿«é€Ÿä¸Šæ‰‹ï¼š
    1.  **å·¦ä¾§ä¸Šä¼ **ï¼šæ‹–å…¥ Excel åº•ç¨¿å’Œ Word é™„æ³¨ã€‚
    2.  **è‡ªåŠ¨åˆ†æ**ï¼šä¸Šä¼ å³ç®—ï¼Œç‚¹å‡»ä¸Šæ–¹æ ‡ç­¾é¡µåˆ‡æ¢ **æ•°æ®è¡¨ / æ–‡æ¡ˆ / å˜åŠ¨åˆ†ææ–‡æ¡ˆ**ã€‚
    3.  **ä¸€é”®å¯¼å‡º**ï¼šæ”¯æŒå¯¼å‡º **ç²¾æ’ç‰ˆ Word è¡¨æ ¼** (å®‹ä½“/åŠ ç²—/1.5ç£…è¾¹æ¡†)ã€‚
    """)
    st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼  Excel æ–‡ä»¶ä»¥å¼€å§‹ä½¿ç”¨ã€‚")

else:
    # âœ… ä¿®å¤ç‚¹ 1ï¼šç›´æ¥å®šä¹‰ä¸ºç©ºåˆ—è¡¨ï¼Œä¸å†å°è¯•è¯»å– uploaded_word_files
    word_data_list = [] 
    
    # âœ… ä¿®å¤ç‚¹ 2ï¼šå®šä¹‰æ•°æ®è¯»å–å‡½æ•° (å¼•ç”¨é»˜è®¤é…ç½®)
    def get_clean_data(target_sheet_name):
        try:
            # ä½¿ç”¨é»˜è®¤çš„ HEADER_ROW = 2
            df, all_sheets_if_failed = fuzzy_load_excel(uploaded_excel, target_sheet_name, DEFAULT_HEADER_ROW)
            if df is None: return None, None, f"æœªæ‰¾åˆ° Sheet '{target_sheet_name}' (ç°æœ‰ Sheet: {all_sheets_if_failed})"
            
            # å°è¯•æˆªå–å‰å‡ åˆ— (å‡è®¾æ ¼å¼æ ‡å‡†)
            df = df.iloc[:, [0, 4, 5, 6]]
            orig_cols = df.columns.tolist()
            d_labels = [extract_date_label(orig_cols[1]), extract_date_label(orig_cols[2]), extract_date_label(orig_cols[3])]
            df.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
            df = df.dropna(subset=['ç§‘ç›®'])
            df['ç§‘ç›®'] = df['ç§‘ç›®'].astype(str).str.strip()
            for c in ['T', 'T_1', 'T_2']:
                df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
            df.set_index('ç§‘ç›®', inplace=True)
            return df, d_labels, None
        except Exception as e: return None, None, str(e)

    st.header(f"ğŸ“Š {analysis_page}")

    # --- é¡µé¢è·¯ç”±é€»è¾‘ ---

    if analysis_page == "(ä¸€) èµ„äº§ç»“æ„åˆ†æ":
        df_asset, d_labels, err = get_clean_data(SHEET_CONFIG["asset"])
        if df_asset is not None: process_analysis_tab(df_asset, word_data_list, "èµ„äº§æ€»è®¡", "èµ„äº§", d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ":
        df_liab, d_labels, err = get_clean_data(SHEET_CONFIG["liab"])
        if df_liab is not None:
            total_name = "è´Ÿå€ºåˆè®¡" 
            if not df_liab.index.str.contains(total_name).any(): total_name = "è´Ÿå€ºæ€»è®¡"
            process_analysis_tab(df_liab, word_data_list, total_name, "è´Ÿå€º", d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(ä¸‰) ç°é‡‘æµé‡åˆ†æ":
        df_cash, d_labels, err = get_clean_data(SHEET_CONFIG["cash"])
        if df_cash is not None:
            process_cash_flow_tab(df_cash, word_data_list, d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(å››) è´¢åŠ¡æŒ‡æ ‡åˆ†æ":
        # è´¢åŠ¡æŒ‡æ ‡è¡¨é€šå¸¸è¡¨å¤´ä¸å›ºå®šï¼Œä½¿ç”¨ fuzzy_load_excel çš„å†…éƒ¨é€»è¾‘
        df_ratios, d_labels = fuzzy_load_excel(uploaded_excel, SHEET_CONFIG["ratios"], DEFAULT_HEADER_ROW)
        if df_ratios is not None:
            process_financial_ratios_tab(df_ratios, word_data_list, d_labels)
        else: 
            st.error(f"âŒ è¯»å–å¤±è´¥ï¼šæœªæ‰¾åˆ° Sheet '{SHEET_CONFIG['ratios']}'")

    elif analysis_page == "(äº”) ç›ˆåˆ©èƒ½åŠ›åˆ†æ":
        df_profit, d_labels, err = get_clean_data(SHEET_CONFIG["profit"])
        if df_profit is not None:
            process_profitability_tab(df_profit, word_data_list, d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")
