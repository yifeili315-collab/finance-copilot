import streamlit as st
import pandas as pd
import re
from docx import Document
from docx.shared import Pt, Cm
from docx.oxml.ns import qn
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_CELL_VERTICAL_ALIGNMENT, WD_ROW_HEIGHT_RULE
from docx.oxml import OxmlElement
import io

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="æ™ºèƒ½è´¢åŠ¡åˆ†æç³»ç»Ÿ", 
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# ================= 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° =================

def set_cell_border(cell, **kwargs):
    """è®¾ç½®å•å…ƒæ ¼è¾¹æ¡†"""
    tc = cell._tc
    tcPr = tc.get_or_add_tcPr()
    for border_name in ["top", "left", "bottom", "right", "insideH", "insideV"]:
        if border_name in kwargs:
            edge = kwargs[border_name]
            tcBorders = tcPr.first_child_found_in("w:tcBorders")
            if tcBorders is None:
                tcBorders = OxmlElement('w:tcBorders')
                tcPr.append(tcBorders)
            border = OxmlElement(f'w:{border_name}')
            border.set(qn('w:val'), edge.get('val', 'single'))
            border.set(qn('w:sz'), str(edge.get('sz', 4)))
            border.set(qn('w:space'), str(edge.get('space', 0)))
            border.set(qn('w:color'), edge.get('color', 'auto'))
            tcBorders.append(border)

def create_word_table_file(df, title="æ•°æ®è¡¨"):
    """ğŸ”¥ ç”Ÿæˆç²¾æ’ç‰ˆ Word è¡¨æ ¼ (å®‹ä½“+ç²—è¾¹æ¡†)"""
    doc = Document()
    
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
    style.font.size = Pt(10.5)

    heading = doc.add_heading(title, level=1)
    heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in heading.runs:
        run.font.name = 'Times New Roman'
        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“') # æ ‡é¢˜ç”¨å®‹ä½“åŠ ç²—
        run.font.bold = True
        run.font.color.rgb = None

    export_df = df.reset_index()
    table = doc.add_table(rows=1, cols=len(export_df.columns))
    table.alignment = WD_ALIGN_PARAGRAPH.CENTER
    table.autofit = False 
    
    col_widths = [Cm(3.5)] + [Cm(2.2)] * (len(export_df.columns) - 1)
    for i, width in enumerate(col_widths):
        for row in table.rows:
            row.cells[i].width = width

    # --- è¡¨å¤´ (å®‹ä½“åŠ ç²—) ---
    hdr_cells = table.rows[0].cells
    table.rows[0].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
    table.rows[0].height = Cm(0.6)

    for i, col_name in enumerate(export_df.columns):
        cell = hdr_cells[i]
        cell.text = str(col_name)
        
        top_sz = 12
        bottom_sz = 12 
        left_sz = 12 if i == 0 else 4
        right_sz = 12 if i == len(export_df.columns) - 1 else 4

        set_cell_border(cell, 
                        top={"val": "single", "sz": top_sz}, 
                        bottom={"val": "single", "sz": bottom_sz}, 
                        left={"val": "single", "sz": left_sz}, 
                        right={"val": "single", "sz": right_sz})
        
        cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
        paragraph = cell.paragraphs[0]
        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
        paragraph.paragraph_format.line_spacing = 1.0 
        paragraph.paragraph_format.space_before = Pt(0) 
        paragraph.paragraph_format.space_after = Pt(0)  

        for run in paragraph.runs:
            run.font.bold = True
            run.font.size = Pt(10.5)
            run.font.name = 'Times New Roman'
            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

    # --- æ•°æ®å¡«å…… ---
    for r_idx, row in export_df.iterrows():
        row_cells = table.add_row().cells
        table.rows[r_idx+1].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
        table.rows[r_idx+1].height = Cm(0.6)

        subject_name = str(row[0])
        is_bold_row = "åˆè®¡" in subject_name or "æ€»è®¡" in subject_name

        for i, val in enumerate(row):
            cell = row_cells[i]
            cell.text = str(val)
            
            bottom_sz = 12 if r_idx == len(export_df) - 1 else 4
            left_sz = 12 if i == 0 else 4
            right_sz = 12 if i == len(export_df.columns) - 1 else 4
            
            set_cell_border(cell, 
                            top={"val": "single", "sz": 4}, 
                            bottom={"val": "single", "sz": bottom_sz}, 
                            left={"val": "single", "sz": left_sz}, 
                            right={"val": "single", "sz": right_sz})
            
            cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
            paragraph = cell.paragraphs[0]
            
            if i == 0:
                paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            else:
                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
            
            paragraph.paragraph_format.line_spacing = 1.0
            paragraph.paragraph_format.space_before = Pt(0)
            paragraph.paragraph_format.space_after = Pt(0)

            for run in paragraph.runs:
                run.font.size = Pt(9)
                run.font.name = 'Times New Roman'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                if is_bold_row:
                    run.font.bold = True
            
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def create_excel_file(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='æ•°æ®æ˜ç»†')
    output.seek(0)
    return output

def load_single_word(file_obj):
    """è¯»å– Word è¿”å›å†…å®¹"""
    try:
        file_obj.seek(0)
        doc = Document(file_obj)
        full_text = [p.text.strip() for p in doc.paragraphs if len(p.text.strip()) > 5]
        return "\n".join(full_text), True, ""
    except Exception as e:
        error_msg = str(e)
        if "is not a zip file" in error_msg:
            friendly_msg = (
                f"âŒ **ã€æ ¼å¼é”™è¯¯ã€‘** æ–‡ä»¶ï¼š{file_obj.name}\n\n"
                f"**åŸå› **ï¼šè¿™æ˜¯ä¸€ä¸ªâ€œä¼ªè£…â€çš„ .docx æ–‡ä»¶ã€‚\n\n"
                f"ğŸ‘‰ **è§£å†³æ–¹æ³•ï¼š**\n"
                f"1. åœ¨ç”µè„‘ä¸Šç”¨ Word æ‰“å¼€è¯¥æ–‡ä»¶ã€‚\n"
                f"2. ç‚¹å‡»å·¦ä¸Šè§’ã€æ–‡ä»¶ã€‘->ã€å¦å­˜ä¸ºã€‘ã€‚\n"
                f"3. æ–‡ä»¶ç±»å‹åŠ¡å¿…æ‰‹åŠ¨é€‰æ‹©ã€Word æ–‡æ¡£ (*.docx)ã€‘ã€‚\n"
                f"4. ä¿å­˜åï¼Œä¸Šä¼ æ–°çš„æ–‡ä»¶å³å¯ã€‚"
            )
            return "", False, friendly_msg
        else:
            return "", False, f"âŒ è¯»å–å¤±è´¥ {file_obj.name}: {error_msg}"

def find_context(subject, word_data_list):
    """
    ğŸ”¥ å¤šæ–‡ä»¶ RAG æ£€ç´¢
    word_data_list: [{'source': 'æ–‡ä»¶å', 'content': 'å†…å®¹'}, ...]
    """
    if not word_data_list: return ""
    
    clean_sub = subject.replace(" ", "")
    found_contexts = []
    
    for item in word_data_list:
        content = item['content']
        source = item['source']
        
        idx = content.find(clean_sub)
        if idx != -1:
            # æ‰¾åˆ°å…³é”®è¯ï¼Œæˆªå–å‰åæ–‡
            start = max(0, idx - 600)
            end = min(len(content), idx + 1200)
            ctx = content[start:end].replace('\n', ' ')
            # ğŸ”¥ åŠ ä¸Šæ¥æºæ ‡è®°
            found_contexts.append(f"ğŸ“„ **æ¥æºï¼š{source}**\n{ctx}")
            
    if not found_contexts:
        return "ï¼ˆæœªæ£€ç´¢åˆ°ç›¸å…³é™„æ³¨ï¼‰"
    
    return "\n\n".join(found_contexts)

def extract_date_label(header_str):
    s = str(header_str).strip()
    match = re.search(r'[ã€\[](.*?)[ã€‘\]]', s)
    if match: return match.group(1)
    year = re.search(r'(\d{4})', s)
    if year: return f"{year.group(1)}å¹´"
    return s

def safe_pct(num, denom):
    return (num / denom * 100) if denom != 0 else 0.0

def process_analysis_tab(df_raw, word_data_list, total_col_name, analysis_name, d_labels):
    """æ ¸å¿ƒåˆ†æå‡½æ•°"""
    try:
        total_row = df_raw[df_raw.index.str.contains(total_col_name)].iloc[0]
    except:
        st.error(f"âŒ åˆ†æä¸­æ–­ï¼šåœ¨è¡¨ä¸­æœªæ‰¾åˆ° '{total_col_name}' è¡Œï¼Œè¯·æ£€æŸ¥ Excel ç§‘ç›®åç§°æˆ– Sheet é€‰æ‹©æ˜¯å¦æ­£ç¡®ã€‚")
        return

    df = df_raw.copy()
    for period in ['T', 'T_1', 'T_2']:
        total = total_row[period]
        if total != 0:
            df[f'å æ¯”_{period}'] = df[period] / total
        else:
            df[f'å æ¯”_{period}'] = 0.0

    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ æ˜ç»†æ•°æ®", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ¤– AI åˆ†ææŒ‡ä»¤"])

    with tab1:
        c1, c2, c3 = st.columns([6, 1.2, 1.2]) 
        with c1: st.markdown(f"### {analysis_name}ç»“æ„æ˜ç»†")
        
        display_df = df.copy()
        for p in ['T', 'T_1', 'T_2']:
            display_df[f'fmt_{p}'] = display_df[p].apply(lambda x: f"{x:,.2f}")
            display_df[f'fmt_pct_{p}'] = (display_df[f'å æ¯”_{p}'] * 100).apply(lambda x: f"{x:.2f}")

        d_t, d_t1, d_t2 = d_labels
        final_df = pd.DataFrame(index=display_df.index)
        final_df[f"{d_t}"] = display_df['fmt_T']
        final_df["å æ¯”(%) "] = display_df['fmt_pct_T']
        final_df[f"{d_t1}"] = display_df['fmt_T_1']
        final_df["å æ¯”(%)"] = display_df['fmt_pct_T_1']
        final_df[f"{d_t2}"] = display_df['fmt_T_2']
        final_df[" å æ¯”(%)"] = display_df['fmt_pct_T_2']

        with c2:
            doc_file = create_word_table_file(final_df, title=f"{analysis_name}ç»“æ„æƒ…å†µè¡¨")
            st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, f"{analysis_name}æ˜ç»†.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
        with c3:
            excel_file = create_excel_file(final_df)
            st.download_button(f"ğŸ“¥ ä¸‹è½½ Excel", excel_file, f"{analysis_name}æ˜ç»†.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        
        st.dataframe(final_df, use_container_width=True)

    with tab2:
        st.markdown("ğŸ‘‡ **ç›´æ¥å¤åˆ¶ï¼š**")
        top_5 = df.sort_values(by='T', ascending=False).head(5).index.tolist()
        text = ""
        try:
            if analysis_name == "èµ„äº§":
                curr_row = df_raw[df_raw.index.str.contains('æµåŠ¨èµ„äº§åˆè®¡')].iloc[0]
                non_curr_row = df_raw[df_raw.index.str.contains('éæµåŠ¨èµ„äº§åˆè®¡')].iloc[0]
                text = (
                    f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººèµ„äº§æ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                    f"å…¶ä¸­ï¼ŒæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{curr_row['T_2']:,.2f}ä¸‡å…ƒã€{curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                    f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(curr_row['T_2'], total_row['T_2']):.2f}%ã€"
                    f"{safe_pct(curr_row['T_1'], total_row['T_1']):.2f}%å’Œ"
                    f"{safe_pct(curr_row['T'], total_row['T']):.2f}%ï¼›\n\n"
                    f"éæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{non_curr_row['T_2']:,.2f}ä¸‡å…ƒã€{non_curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{non_curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                    f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(non_curr_row['T_2'], total_row['T_2']):.2f}%ã€"
                    f"{safe_pct(non_curr_row['T_1'], total_row['T_1']):.2f}%å’Œ"
                    f"{safe_pct(non_curr_row['T'], total_row['T']):.2f}%ã€‚\n\n"
                    f"åœ¨æ€»èµ„äº§æ„æˆä¸­ï¼Œå…¬å¸èµ„äº§ä¸»è¦ä¸º **{'ã€'.join(top_5)}** ç­‰ã€‚"
                )
            elif analysis_name == "è´Ÿå€º":
                curr_row = df_raw[df_raw.index.str.contains('æµåŠ¨è´Ÿå€ºåˆè®¡')].iloc[0]
                non_curr_row = df_raw[df_raw.index.str.contains('éæµåŠ¨è´Ÿå€ºåˆè®¡')].iloc[0]
                text = (
                    f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººè´Ÿå€ºæ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                    f"å…¶ä¸­ï¼ŒæµåŠ¨è´Ÿå€ºé‡‘é¢åˆ†åˆ«ä¸º{curr_row['T_2']:,.2f}ä¸‡å…ƒã€{curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                    f"å è´Ÿå€ºæ€»é¢çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(curr_row['T_2'], total_row['T_2']):.2f}%ã€"
                    f"{safe_pct(curr_row['T_1'], total_row['T_1']):.2f}%å’Œ"
                    f"{safe_pct(curr_row['T'], total_row['T']):.2f}%ï¼›\n\n"
                    f"éæµåŠ¨è´Ÿå€ºé‡‘é¢åˆ†åˆ«ä¸º{non_curr_row['T_2']:,.2f}ä¸‡å…ƒã€{non_curr_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{non_curr_row['T']:,.2f}ä¸‡å…ƒï¼Œ"
                    f"å è´Ÿå€ºæ€»é¢çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(non_curr_row['T_2'], total_row['T_2']):.2f}%ã€"
                    f"{safe_pct(non_curr_row['T_1'], total_row['T_1']):.2f}%å’Œ"
                    f"{safe_pct(non_curr_row['T'], total_row['T']):.2f}%ã€‚\n\n"
                    f"ä»ç»“æ„æ¥çœ‹ï¼Œä¸»è¦æ„æˆé¡¹ç›®åŒ…æ‹¬ï¼š**{'ã€'.join(top_5)}** ç­‰ã€‚"
                )
            else:
                text = f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäºº{analysis_name}æ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\nä¸»è¦æ„æˆé¡¹ç›®åŒ…æ‹¬ï¼š**{'ã€'.join(top_5)}** ç­‰ã€‚"
        except:
             text = f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäºº{analysis_name}æ€»é¢åˆ†åˆ«ä¸º{total_row['T_2']:,.2f}ä¸‡å…ƒã€{total_row['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_row['T']:,.2f}ä¸‡å…ƒã€‚\nä¸»è¦æ„æˆé¡¹ç›®åŒ…æ‹¬ï¼š**{'ã€'.join(top_5)}** ç­‰ã€‚"
        
        st.code(text, language='text')

    with tab3:
        st.info(f"ğŸ’¡ **æç¤º**ï¼šä»¥ä¸‹æ˜¯åŸºäº **{d_t} (æœ€æ–°ä¸€æœŸ)** å æ¯”å‰åˆ—çš„ç§‘ç›®ç”Ÿæˆçš„åˆ†ææŒ‡ä»¤ã€‚")
        st.caption("ğŸ‘‰ ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶ï¼Œå‘é€ç»™ AI (DeepSeek/ChatGPT)ã€‚")
        
        exclude_list = ['åˆè®¡', 'æ€»è®¡', 'æ€»é¢']
        major_subjects = df[
            (df['å æ¯”_T'] > 0.01) & 
            (~df.index.str.contains('|'.join(exclude_list)))
        ].index.tolist()
        
        for subject in major_subjects:
            row = df.loc[subject]
            diff = row['T'] - row['T_1']
            pct = safe_pct(diff, row['T_1'])
            direction = "å¢åŠ " if diff >= 0 else "å‡å°‘"
            pct_label = "å¢å¹…" if diff >= 0 else "é™å¹…"
            
            prompt = f"""ã€ä»»åŠ¡ã€‘åˆ†æâ€œ{subject}â€å˜åŠ¨åŸå› ã€‚
ã€1. æ•°æ®è¶‹åŠ¿ã€‘
{d_t2}ã€{d_t1}åŠ{d_t}ï¼Œä½™é¢åˆ†åˆ«ä¸º{row['T_2']:,.2f}ä¸‡å…ƒã€{row['T_1']:,.2f}ä¸‡å…ƒå’Œ{row['T']:,.2f}ä¸‡å…ƒï¼Œå æ¯”åˆ†åˆ«ä¸º{row['å æ¯”_T_2']*100:.2f}%ã€{row['å æ¯”_T_1']*100:.2f}%å’Œ{row['å æ¯”_T']*100:.2f}%ã€‚
ã€2. å˜åŠ¨æƒ…å†µã€‘
æˆªè‡³{d_t}ï¼Œè¾ƒä¸ŠæœŸ{direction}{abs(diff):,.2f}ä¸‡å…ƒï¼Œ{pct_label}{abs(pct):.2f}%ã€‚
ã€3. é™„æ³¨çº¿ç´¢ã€‘
{find_context(subject, word_data_list)}
ã€4. å†™ä½œè¦æ±‚ã€‘
ç»“åˆæ•°æ®å’Œé™„æ³¨åˆ†æåŸå› ã€‚å¦‚é™„æ³¨æœªæåŠï¼Œå†™â€œä¸»è¦ç³»ä¸šåŠ¡è§„æ¨¡å˜åŠ¨æ‰€è‡´â€ã€‚"""
            
            with st.expander(f"ğŸ“Œ {subject} (å æ¯” {row['å æ¯”_T']:.2%})"):
                st.code(prompt, language='text')

# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.title("ğŸ›ï¸ æ“æ§å°")
    analysis_page = st.radio("è¯·é€‰æ‹©è¦ç”Ÿæˆçš„ç« èŠ‚ï¼š", ["(ä¸€) èµ„äº§ç»“æ„åˆ†æ", "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ", "(ä¸‰) ç°é‡‘æµé‡åˆ†æ (å¼€å‘ä¸­...)", "(å››) è´¢åŠ¡æŒ‡æ ‡åˆ†æ (å¼€å‘ä¸­...)"])
    st.markdown("---")
    
    # ğŸ”¥ æ–°å¢ï¼šæ•°æ®åˆ—æ¨¡å¼é€‰æ‹©
    data_col_mode = st.radio(
        "ğŸ“Š æ•°æ®åˆ—è¯»å–æ¨¡å¼ï¼š",
        ("ğŸ”¹ æ ‡å‡†æ¨¡ç‰ˆ (è‡ªåŠ¨è¯»E/F/Gåˆ—)", "ğŸ”§ è‡ªå®šä¹‰æ¨¡å¼ (æ‰‹åŠ¨é€‰3åˆ—)"),
        help="ã€æ ‡å‡†æ¨¡ç‰ˆã€‘ï¼šé€‚ç”¨äºå…¬å¸æ ‡å‡†åº•ç¨¿ï¼ˆç¬¬5,6,7åˆ—ä¸ºä¸‡å…ƒæ•°æ®ï¼‰ã€‚\nã€è‡ªå®šä¹‰æ¨¡å¼ã€‘ï¼šé€‚ç”¨äºä»»æ„æ ¼å¼è¡¨ï¼Œç”±ä½ æŒ‡å®šå“ªä¸‰åˆ—æ˜¯æ•°æ®ã€‚"
    )
    
    st.markdown("---")
    uploaded_excel = st.file_uploader("Excel åº•ç¨¿ (å¿…é¡»)", type=["xlsx", "xlsm"])
    uploaded_word_files = st.file_uploader("Word é™„æ³¨ (å¯é€‰)", type=["docx"], accept_multiple_files=True)
    header_row = st.number_input("è¡¨å¤´æ‰€åœ¨è¡Œ (é»˜è®¤2)", value=2)
    st.markdown("### 3. Excel Sheet åŒ¹é…")
    sheet_asset = st.text_input("èµ„äº§è¡¨ Sheet å", value="1.åˆå¹¶èµ„äº§è¡¨")
    sheet_liab = st.text_input("è´Ÿå€ºè¡¨ Sheet å", value="2.åˆå¹¶è´Ÿå€ºè¡¨") 

# ================= 4. ä¸»ç¨‹åº =================

if not uploaded_excel:
    st.title("ğŸ“Š è´¢åŠ¡åˆ†ææŠ¥å‘Šè‡ªåŠ¨åŒ–åŠ©æ‰‹")
    st.markdown("""
    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š
    1. **ä¸Šä¼  Excel åº•ç¨¿ (å¿…é¡»)**ï¼šè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ ã€‚
    2. **ä¸Šä¼  Word é™„æ³¨ (å¯é€‰)**ï¼šæ”¯æŒä¸Šä¼ å¤šä¸ª Word æ–‡ä»¶ï¼Œç”¨äºç”ŸæˆåŸå› åˆ†æã€‚
    3. **é€‰æ‹©è¯»å–æ¨¡å¼**ï¼š
       - å¦‚æœæ˜¯æ ‡å‡†æ¨¡ç‰ˆï¼Œç›´æ¥ç”¨ **æ ‡å‡†æ¨¡ç‰ˆ**ã€‚
       - å¦‚æœæ˜¯æ™®é€šè¡¨æ ¼ï¼Œè¯·åˆ‡æ¢åˆ° **è‡ªå®šä¹‰æ¨¡å¼** å¹¶æ‰‹åŠ¨å‹¾é€‰ä¸‰åˆ—æ•°æ®ã€‚
    4. **ä¸€é”®å¯¼å‡º**ï¼šæ”¯æŒå¯¼å‡º **ç²¾æ’ç‰ˆ Word è¡¨æ ¼**ï¼Œç›´æ¥ç²˜è´´åˆ°æŠ¥å‘Šä¸­ã€‚
    """)
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼  Excel æ–‡ä»¶ä»¥å¼€å§‹ä½¿ç”¨ã€‚")

else:
    # Word å¤„ç†é€»è¾‘
    word_data_list = []
    word_error_msgs = []
    if uploaded_word_files:
        for w in uploaded_word_files:
            content, success, err_msg = load_single_word(w) 
            if success:
                word_data_list.append({'source': w.name, 'content': content})
            else:
                word_error_msgs.append(err_msg)
    if word_error_msgs:
        for msg in word_error_msgs: st.error(msg)
    elif uploaded_word_files: st.success(f"âœ… æˆåŠŸè¯»å– {len(word_data_list)} ä¸ª Word æ–‡ä»¶ï¼")

    # ğŸ”¥ æ ¸å¿ƒå‡çº§ï¼šäº¤äº’å¼æ•°æ®è¯»å–é€»è¾‘
    def get_clean_data(sheet_name):
        try:
            # 1. å…ˆè¯»å…¨éƒ¨æ•°æ®
            df_full = pd.read_excel(uploaded_excel, sheet_name=sheet_name, header=header_row)
            
            # 2. è·å–æ‰€æœ‰åˆ—å
            all_cols = df_full.columns.tolist()
            
            # 3. ç¡®å®šæ•°æ®åˆ—
            target_cols = []
            
            if "æ ‡å‡†æ¨¡ç‰ˆ" in data_col_mode:
                # é»˜è®¤è¯»å– E, F, G (ç´¢å¼• 4, 5, 6)
                if len(all_cols) > 6:
                    target_cols = [all_cols[0], all_cols[4], all_cols[5], all_cols[6]]
                else:
                    st.error("âŒ æ ‡å‡†æ¨¡ç‰ˆæ¨¡å¼ä¸‹ï¼Œè¡¨æ ¼åˆ—æ•°ä¸è¶³ 7 åˆ—ï¼Œè¯·åˆ‡æ¢åˆ°ã€è‡ªå®šä¹‰æ¨¡å¼ã€‘ã€‚")
                    return None, None, "åˆ—æ•°ä¸è¶³"
            else:
                # ğŸ”§ è‡ªå®šä¹‰æ¨¡å¼ï¼šæ˜¾ç¤ºå¤šé€‰æ¡†è®©ç”¨æˆ·é€‰
                st.info("ğŸ‘‡ **ã€é€šç”¨æ¨¡å¼ã€‘è¯·åœ¨ä¸‹æ–¹é€‰æ‹© 3 åˆ—åŒ…å«æ•°æ®çš„åˆ—**ï¼ˆè¯·æŒ‰é¡ºåºï¼šæœ€æ–°ä¸€æœŸ -> ä¸ŠæœŸ -> ä¸Šä¸ŠæœŸï¼‰ï¼š")
                
                # æ’é™¤ç¬¬ä¸€åˆ—ï¼ˆé€šå¸¸æ˜¯ç§‘ç›®ï¼‰ï¼Œè®©ç”¨æˆ·é€‰æ•°æ®åˆ—
                user_selected = st.multiselect(
                    "è¯·å‹¾é€‰åˆ—ï¼ˆéœ€é€‰3ä¸ªï¼‰ï¼š",
                    options=all_cols,
                    default=all_cols[1:4] if len(all_cols) >= 4 else None,
                    key=f"cols_{sheet_name}" # é¿å…Keyå†²çª
                )
                
                if len(user_selected) != 3:
                    st.warning("âš ï¸ è¯·å¿…é¡»ä¸”åªèƒ½é€‰æ‹© **3** åˆ—æ•°æ®ï¼")
                    st.stop() # æš‚åœå¾€ä¸‹æ‰§è¡Œï¼Œç­‰å¾…ç”¨æˆ·é€‰å¥½
                
                # æ‹¼è£…ï¼š[ç§‘ç›®åˆ—] + [ç”¨æˆ·é€‰çš„3åˆ—]
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾ç¬¬ä¸€åˆ—æ°¸è¿œæ˜¯ç§‘ç›®ã€‚
                # ä¸ºäº†é˜²æ­¢ç”¨æˆ·æŠŠç§‘ç›®åˆ—ä¹Ÿé€‰è¿›å»äº†ï¼Œæˆ‘ä»¬å¼ºåˆ¶ä½¿ç”¨ df_full.iloc[:, 0] ä½œä¸ºç§‘ç›®åˆ—
                df_subject = df_full.iloc[:, [0]]
                df_data = df_full[user_selected]
                
                # åˆå¹¶
                df = pd.concat([df_subject, df_data], axis=1)
            
            if "æ ‡å‡†æ¨¡ç‰ˆ" in data_col_mode:
                df = df_full.iloc[:, target_cols].copy()

            # 5. æå–æ—¥æœŸæ ‡ç­¾
            orig_cols = df.columns.tolist()
            d_labels = [extract_date_label(orig_cols[1]), extract_date_label(orig_cols[2]), extract_date_label(orig_cols[3])]
            
            # 6. æ ‡å‡†åŒ–å¤„ç†
            df.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
            df = df.dropna(subset=['ç§‘ç›®'])
            df['ç§‘ç›®'] = df['ç§‘ç›®'].astype(str).str.strip()
            for c in ['T', 'T_1', 'T_2']:
                df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
            df.set_index('ç§‘ç›®', inplace=True)
            return df, d_labels, None

        except Exception as e:
            return None, None, str(e)

    st.header(f"ğŸ“Š {analysis_page}")

    if analysis_page == "(ä¸€) èµ„äº§ç»“æ„åˆ†æ":
        df_asset, d_labels, err = get_clean_data(sheet_asset)
        
        if df_asset is not None:
            process_analysis_tab(df_asset, word_data_list, "èµ„äº§æ€»è®¡", "èµ„äº§", d_labels)
        elif err != "åˆ—æ•°ä¸è¶³": 
            st.error(f"âŒ è¯»å– Excel å¤±è´¥ï¼š{err}\nè¯·æ£€æŸ¥ã€èµ„äº§è¡¨ Sheet åã€‘æ˜¯å¦ä¸ºï¼š{sheet_asset}")

    elif analysis_page == "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ":
        df_liab, d_labels, err = get_clean_data(sheet_liab)
        if df_liab is not None:
            total_name = "è´Ÿå€ºåˆè®¡" 
            if not df_liab.index.str.contains(total_name).any():
                total_name = "è´Ÿå€ºæ€»è®¡"
            process_analysis_tab(df_liab, word_data_list, total_name, "è´Ÿå€º", d_labels)
        elif err != "åˆ—æ•°ä¸è¶³":
            st.error(f"âŒ è¯»å– Excel å¤±è´¥ï¼š{err}\nè¯·æ£€æŸ¥ã€è´Ÿå€ºè¡¨ Sheet åã€‘æ˜¯å¦ä¸ºï¼š{sheet_liab}")

    else:
        st.info("ğŸš§ è¯¥æ¨¡å—æ­£åœ¨æ–½å·¥ä¸­ï¼Œæ•¬è¯·æœŸå¾…åç»­æ›´æ–°...")
