import streamlit as st
import pandas as pd
import re
from docx import Document
from docx.shared import Pt, Cm
from docx.oxml.ns import qn
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.table import WD_CELL_VERTICAL_ALIGNMENT, WD_ROW_HEIGHT_RULE
from docx.oxml import OxmlElement
import io

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="æ™ºèƒ½è´¢åŠ¡åˆ†æç³»ç»Ÿ", 
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# ================= 2. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def set_cell_border(cell, **kwargs):
    """è®¾ç½®å•å…ƒæ ¼è¾¹æ¡†"""
    tc = cell._tc
    tcPr = tc.get_or_add_tcPr()
    for border_name in ["top", "left", "bottom", "right", "insideH", "insideV"]:
        if border_name in kwargs:
            edge = kwargs[border_name]
            tcBorders = tcPr.first_child_found_in("w:tcBorders")
            if tcBorders is None:
                tcBorders = OxmlElement('w:tcBorders')
                tcPr.append(tcBorders)
            border = OxmlElement(f'w:{border_name}')
            border.set(qn('w:val'), edge.get('val', 'single'))
            border.set(qn('w:sz'), str(edge.get('sz', 4)))
            border.set(qn('w:space'), str(edge.get('space', 0)))
            border.set(qn('w:color'), edge.get('color', 'auto'))
            tcBorders.append(border)

def create_word_table_file(df, title="æ•°æ®è¡¨", bold_rows=None):
    """ğŸ”¥ ç”Ÿæˆç²¾æ’ç‰ˆ Word è¡¨æ ¼ (å®¡è®¡åº•ç¨¿é£æ ¼)"""
    doc = Document()
    
    # è®¾ç½®é¡µè¾¹è·ä¸ºçª„è¾¹è·
    section = doc.sections[0]
    section.left_margin = Cm(1.27)
    section.right_margin = Cm(1.27)
    section.top_margin = Cm(1.27)
    section.bottom_margin = Cm(1.27)

    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
    style.font.size = Pt(10.5)

    heading = doc.add_heading(title, level=1)
    heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in heading.runs:
        run.font.name = 'Times New Roman'
        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“') 
        run.font.bold = True
        run.font.color.rgb = None

    export_df = df.reset_index()
    table = doc.add_table(rows=1, cols=len(export_df.columns))
    table.alignment = WD_ALIGN_PARAGRAPH.CENTER
    table.autofit = False 
    
    # åŠ¨æ€è®¡ç®—åˆ—å®½
    num_cols = len(export_df.columns)
    if num_cols > 5:
        first_col_w = Cm(5.0)
        other_col_w = Cm(2.2) 
    else:
        first_col_w = Cm(6.0)
        other_col_w = Cm(3.0)

    col_widths = [first_col_w] + [other_col_w] * (num_cols - 1)
    
    for i, width in enumerate(col_widths):
        for row in table.rows:
            row.cells[i].width = width

    hdr_cells = table.rows[0].cells
    table.rows[0].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
    table.rows[0].height = Cm(1.0)

    for i, col_name in enumerate(export_df.columns):
        cell = hdr_cells[i]
        cell.text = str(col_name)
        set_cell_border(cell, top={"val": "single", "sz": 12}, bottom={"val": "single", "sz": 12}, left={"val": "single", "sz": 4}, right={"val": "single", "sz": 4})
        cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
        paragraph = cell.paragraphs[0]
        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER 
        paragraph.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
        paragraph.paragraph_format.space_before = Pt(0)
        paragraph.paragraph_format.space_after = Pt(0)
        
        for run in paragraph.runs:
            run.font.bold = True
            run.font.size = Pt(10.5)
            run.font.name = 'Times New Roman'
            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')

    for r_idx, row in export_df.iterrows():
        row_cells = table.add_row().cells
        table.rows[r_idx+1].height_rule = WD_ROW_HEIGHT_RULE.AT_LEAST
        table.rows[r_idx+1].height = Cm(0.6)
        
        subject_name = str(row[0]).strip()
        is_bold = False
        if bold_rows and subject_name in bold_rows: is_bold = True
        elif any(k in subject_name for k in ["åˆè®¡", "æ€»è®¡", "å‡€é¢", "å‡€å¢åŠ é¢", "æ„æˆ"]): is_bold = True
        elif subject_name.endswith("ï¼š") or subject_name.endswith(":"): is_bold = True

        for i, val in enumerate(row):
            cell = row_cells[i]
            cell.text = str(val) if pd.notna(val) and val != "" else ""
            bottom_sz = 12 if r_idx == len(export_df) - 1 else 4
            set_cell_border(cell, top={"val": "single", "sz": 4}, bottom={"val": "single", "sz": bottom_sz}, left={"val": "single", "sz": 4}, right={"val": "single", "sz": 4})
            cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER
            
            paragraph = cell.paragraphs[0]
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            paragraph.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE
            paragraph.paragraph_format.space_before = Pt(0)
            paragraph.paragraph_format.space_after = Pt(0)

            for run in paragraph.runs:
                run.font.size = Pt(10.5)
                run.font.name = 'Times New Roman'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                if is_bold: run.font.bold = True
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def extract_date_label(header_str):
    s = str(header_str).strip()
    match = re.search(r'[ã€\[](.*?)[ã€‘\]]', s)
    if match: return match.group(1)
    year = re.search(r'(\d{4})', s)
    if year: return f"{year.group(1)}å¹´"
    return s

def fuzzy_load_excel(file_obj, sheet_name, header_row=None):
    try:
        xl = pd.ExcelFile(file_obj)
        all_sheet_names = xl.sheet_names
        target_sheet = None
        
        if sheet_name in all_sheet_names:
            target_sheet = sheet_name
        else:
            clean_target = sheet_name.replace(" ", "")
            for actual_name in all_sheet_names:
                if actual_name.replace(" ", "") == clean_target:
                    target_sheet = actual_name
                    break
        
        if target_sheet is None:
            return None, all_sheet_names

        if "è´¢åŠ¡æŒ‡æ ‡" in sheet_name or "5-3" in sheet_name:
            return smart_load_ratios(file_obj, target_sheet)
        
        return pd.read_excel(file_obj, sheet_name=target_sheet, header=header_row), None

    except Exception as e:
        return None, [str(e)]

def smart_load_ratios(file_obj, sheet_name):
    try:
        df_raw = pd.read_excel(file_obj, sheet_name=sheet_name, header=None)
        header_idx = -1
        for i in range(10):
            row_values = df_raw.iloc[i].astype(str).values
            if any("é¡¹ç›®" in v or "æŒ‡æ ‡" in v for v in row_values):
                header_idx = i
                break
        if header_idx == -1: header_idx = 1
        df = pd.read_excel(file_obj, sheet_name=sheet_name, header=header_idx)
        cols = df.columns.tolist()
        date_col_indices = []
        for idx, col_name in enumerate(cols):
            s = str(col_name)
            if "å¹´" in s or "T" in s or "202" in s or "æœŸ" in s:
                date_col_indices.append(idx)
        if len(date_col_indices) >= 3:
            target_cols = [0] + date_col_indices[:3]
        else:
            target_cols = [0, 2, 3, 4]
        df_final = df.iloc[:, target_cols]
        orig_cols = df_final.columns.tolist()
        d_labels = [extract_date_label(c) for c in orig_cols[1:]]
        df_final.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
        df_final = df_final.dropna(subset=['ç§‘ç›®'])
        df_final['ç§‘ç›®'] = df_final['ç§‘ç›®'].astype(str).str.strip()
        for c in ['T', 'T_1', 'T_2']:
            df_final[c] = pd.to_numeric(df_final[c], errors='coerce').fillna(0)
        df_final.set_index('ç§‘ç›®', inplace=True)
        return df_final, d_labels
    except Exception as e:
        raise Exception(f"æ™ºèƒ½è¯»å–å¤±è´¥: {str(e)}")

def find_row_fuzzy(df, keywords, exclude_keywords=None, default_val=None):
    if isinstance(keywords, str): keywords = [keywords]
    clean_index = df.index.astype(str).str.replace(r'\s+', '', regex=True)
    found_rows = []
    for kw in keywords:
        clean_kw = kw.replace(" ", "")
        mask_exact = clean_index == clean_kw
        mask_contains = clean_index.str.contains(clean_kw, case=False, na=False)
        if exclude_keywords:
            for ex_kw in exclude_keywords:
                clean_ex = ex_kw.replace(" ", "")
                mask_contains = mask_contains & (~clean_index.str.contains(clean_ex, case=False, na=False))
        matched_indices = df.index[mask_exact | mask_contains].tolist()
        for idx in matched_indices:
            row = df.loc[idx]
            if isinstance(row, pd.DataFrame):
                for _, r in row.iterrows(): found_rows.append(r)
            else:
                found_rows.append(row)
    best_row = None
    max_non_zeros = -1
    for row in found_rows:
        non_zeros = 0
        if row['T'] != 0 and pd.notna(row['T']): non_zeros += 1
        if row['T_1'] != 0 and pd.notna(row['T_1']): non_zeros += 1
        if row['T_2'] != 0 and pd.notna(row['T_2']): non_zeros += 1
        if non_zeros > max_non_zeros:
            max_non_zeros = non_zeros
            best_row = row
    if best_row is not None: return best_row
    if default_val is not None: return default_val
    return pd.Series(0, index=df.columns)

# ================= 3. ä¸šåŠ¡é€»è¾‘å¤„ç†å‡½æ•° (Global) =================

def process_analysis_tab(df_raw, word_data_list, total_col_name, analysis_name, d_labels):
    """å¤„ç†èµ„äº§å’Œè´Ÿå€ºç»“æ„åˆ†æ"""
    try:
        total_row = find_row_fuzzy(df_raw, [total_col_name])
        df = df_raw.copy()
        # è¿‡æ»¤æ‰ä¸‰å¹´å‡ä¸º0çš„ç§‘ç›®
        mask_keep = ~((df['T'] == 0) & (df['T_1'] == 0) & (df['T_2'] == 0)) 
        mask_title = df.index.astype(str).str.contains(r'[:ï¼š]')
        df = df[mask_keep | mask_title]

        for period in ['T', 'T_1', 'T_2']:
            total = total_row[period]
            df[f'å æ¯”_{period}'] = df[period] / total if total != 0 else 0.0

        tab1, tab2, tab3 = st.tabs(["ğŸ“‹ æ˜ç»†æ•°æ®", "ğŸ“ ç»¼è¿°æ–‡æ¡ˆ", "ğŸ“ å˜åŠ¨åˆ†ææ–‡æ¡ˆ"])

        with tab1:
            display_df = pd.DataFrame(index=df.index)
            for p, label in zip(['T', 'T_1', 'T_2'], d_labels):
                display_df[label] = df[p].apply(lambda x: f"{x:,.2f}")
                display_df[f"{label}å æ¯”(%)"] = (df[f'å æ¯”_{p}'] * 100).apply(lambda x: f"{x:.2f}")
            
            # æ¸…é™¤æ ‡é¢˜è¡Œçš„æ•°æ®æ˜¾ç¤º
            for idx in display_df.index:
                if str(idx).strip().endswith(("ï¼š", ":")):
                    display_df.loc[idx] = ""
            
            st.dataframe(display_df, use_container_width=True)
            doc_file = create_word_table_file(display_df, title=f"{analysis_name}ç»“æ„æƒ…å†µè¡¨")
            st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, f"{analysis_name}æ˜ç»†.docx")

        with tab2:
            top_5 = df.sort_values(by='T', ascending=False).head(5).index.tolist()
            denom_text = "æ€»èµ„äº§" if analysis_name == "èµ„äº§" else "è´Ÿå€ºæ€»é¢"
            summary_text = f"åœ¨{denom_text}æ„æˆä¸­ï¼Œå‘è¡Œäºº{analysis_name}ä¸»è¦ä¸º **{'ã€'.join(top_5)}** ç­‰ã€‚"
            st.markdown(f"#### ğŸ“ {analysis_name}ç»¼è¿°æ–‡æ¡ˆ")
            st.code(summary_text, language='text')

        with tab3:
            st.info(f"ğŸ’¡ **æç¤º**ï¼šå·²æ ¹æ®æ•°æ®ç”Ÿæˆç§‘ç›®å˜åŠ¨åˆ†ææ–‡æ¡ˆè‰ç¨¿ã€‚")
            major_subjects = df[(df[f'å æ¯”_T'] > 0.01) & (~df.index.str.contains(r'åˆè®¡|æ€»è®¡|æ€»é¢'))].index.tolist()
            for subject in major_subjects:
                row = df.loc[subject]
                diff_curr = row['T'] - row['T_1']
                dir_curr = "å¢åŠ " if diff_curr >= 0 else "å‡å°‘"
                analysis_text = f"{d_labels[0]}æœ«ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_labels[1]}æœ«{dir_curr}{abs(diff_curr):,.2f}ä¸‡å…ƒã€‚"
                with st.expander(f"ğŸ“Œ {subject}"):
                    st.code(analysis_text, language='text')
    except Exception as e:
        st.error(f"å¤„ç†åˆ†æé¡µé¢æ—¶å‡ºé”™: {e}")

def process_cash_flow_tab(df_raw, word_data_list, d_labels):
    """å¤„ç†ç°é‡‘æµé‡åˆ†æ (è¡¥å…¨å‡½æ•°)"""
    st.subheader("ç°é‡‘æµé‡è¡¨åˆ†æ")
    st.dataframe(df_raw, use_container_width=True)
    doc_file = create_word_table_file(df_raw, title="ç°é‡‘æµé‡åˆ†æè¡¨")
    st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, "ç°é‡‘æµåˆ†æ.docx")

def process_profitability_tab(df_raw, word_data_list, d_labels):
    """å¤„ç†ç›ˆåˆ©èƒ½åŠ›åˆ†æ (è¡¥å…¨å‡½æ•°)"""
    st.subheader("ç›ˆåˆ©èƒ½åŠ›åˆ†æ")
    st.dataframe(df_raw, use_container_width=True)
    doc_file = create_word_table_file(df_raw, title="ç›ˆåˆ©èƒ½åŠ›åˆ†æè¡¨")
    st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, "ç›ˆåˆ©èƒ½åŠ›åˆ†æ.docx")

def process_financial_ratios_tab(df_raw, word_data_list, d_labels):
    """å¤„ç†è´¢åŠ¡æŒ‡æ ‡åˆ†æ (è¡¥å…¨å‡½æ•°)"""
    st.subheader("ä¸»è¦è´¢åŠ¡æŒ‡æ ‡åˆ†æ")
    st.dataframe(df_raw, use_container_width=True)
    doc_file = create_word_table_file(df_raw, title="ä¸»è¦è´¢åŠ¡æŒ‡æ ‡è¡¨")
    st.download_button(f"ğŸ“¥ ä¸‹è½½ Word", doc_file, "è´¢åŠ¡æŒ‡æ ‡åˆ†æ.docx")


# ================= 4. ä¾§è¾¹æ ä¸çŠ¶æ€ =================
if 'show_manual' not in st.session_state:
    st.session_state.show_manual = False

def go_to_manual():
    st.session_state.show_manual = True

def go_to_analysis():
    st.session_state.show_manual = False

with st.sidebar:
    st.title("ğŸ›ï¸ æ“æ§å°")
    analysis_page = st.radio(
        "è¯·é€‰æ‹©è¦ç”Ÿæˆçš„ç« èŠ‚ï¼š", 
        ["(ä¸€) èµ„äº§ç»“æ„åˆ†æ", "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ", "(ä¸‰) ç°é‡‘æµé‡åˆ†æ", "(å››) è´¢åŠ¡æŒ‡æ ‡åˆ†æ", "(äº”) ç›ˆåˆ©èƒ½åŠ›åˆ†æ"],
        on_change=go_to_analysis 
    )
    st.markdown("---")
    uploaded_excel = st.file_uploader("Excel åº•ç¨¿ (å¿…é¡»)", type=["xlsx", "xlsm"], on_change=go_to_analysis)
    st.markdown("---")
    if st.button("ğŸ“˜ ä½¿ç”¨è¯´æ˜ä¹¦", use_container_width=True):
        go_to_manual()
        st.rerun()

# ================= 5. ä¸»ç¨‹åºæ‰§è¡Œ =================

# ç³»ç»Ÿé»˜è®¤é…ç½®
DEFAULT_HEADER_ROW = 2 
SHEET_CONFIG = {
    "asset": "1.åˆå¹¶èµ„äº§è¡¨",
    "liab": "2.åˆå¹¶è´Ÿå€ºåŠæƒç›Šè¡¨",
    "profit": "3.åˆå¹¶åˆ©æ¶¦è¡¨",
    "cash": "4.åˆå¹¶ç°é‡‘æµé‡è¡¨",
    "ratios": "5-3ä¸»è¦è´¢åŠ¡æŒ‡æ ‡è®¡ç®—-æ–¹æ¡ˆ3ï¼ˆä¸“ç”¨å…¬å¸å€ºï¼‰"
}

if not uploaded_excel or st.session_state.show_manual:
    st.title("ğŸ“Š è´¢åŠ¡åˆ†ææŠ¥å‘Šè‡ªåŠ¨åŒ–åŠ©æ‰‹")
    st.info("ğŸ’¡ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ç¬¦åˆæ ‡å‡†å®¡è®¡åº•ç¨¿æ¨¡ç‰ˆçš„ Excel æ–‡ä»¶ã€‚")
    if not uploaded_excel:
        st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼  Excel æ–‡ä»¶ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
else:
    # æ¨¡æ‹Ÿç©ºåˆ—è¡¨ (å¦‚æœä¸éœ€è¦RAGåŠŸèƒ½)
    word_data_list = [] 

    def get_clean_data(target_sheet_name):
        try:
            df, all_sheets_if_failed = fuzzy_load_excel(uploaded_excel, target_sheet_name, DEFAULT_HEADER_ROW)
            if df is None: return None, None, f"æœªæ‰¾åˆ° Sheet '{target_sheet_name}' (ç°æœ‰: {all_sheets_if_failed})"
            
            # å°è¯•æˆªå–å‰å‡ åˆ— 
            df = df.iloc[:, [0, 4, 5, 6]]
            orig_cols = df.columns.tolist()
            d_labels = [extract_date_label(orig_cols[1]), extract_date_label(orig_cols[2]), extract_date_label(orig_cols[3])]
            df.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
            df = df.dropna(subset=['ç§‘ç›®'])
            df['ç§‘ç›®'] = df['ç§‘ç›®'].astype(str).str.strip()
            for c in ['T', 'T_1', 'T_2']:
                df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
            df.set_index('ç§‘ç›®', inplace=True)
            return df, d_labels, None
        except Exception as e: return None, None, str(e)

    st.header(f"ğŸ“Š {analysis_page}")

    if analysis_page == "(ä¸€) èµ„äº§ç»“æ„åˆ†æ":
        df_asset, d_labels, err = get_clean_data(SHEET_CONFIG["asset"])
        if df_asset is not None: 
            process_analysis_tab(df_asset, word_data_list, "èµ„äº§æ€»è®¡", "èµ„äº§", d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(äºŒ) è´Ÿå€ºç»“æ„åˆ†æ":
        df_liab, d_labels, err = get_clean_data(SHEET_CONFIG["liab"])
        if df_liab is not None:
            total_name = "è´Ÿå€ºåˆè®¡" 
            if not find_row_fuzzy(df_liab, total_name).any() and find_row_fuzzy(df_liab, "è´Ÿå€ºæ€»è®¡").any():
                total_name = "è´Ÿå€ºæ€»è®¡"
            process_analysis_tab(df_liab, word_data_list, total_name, "è´Ÿå€º", d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(ä¸‰) ç°é‡‘æµé‡åˆ†æ":
        df_cash, d_labels, err = get_clean_data(SHEET_CONFIG["cash"])
        if df_cash is not None:
            process_cash_flow_tab(df_cash, word_data_list, d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")

    elif analysis_page == "(å››) è´¢åŠ¡æŒ‡æ ‡åˆ†æ":
        df_ratios, d_labels = fuzzy_load_excel(uploaded_excel, SHEET_CONFIG["ratios"], DEFAULT_HEADER_ROW)
        if df_ratios is not None:
            process_financial_ratios_tab(df_ratios, word_data_list, d_labels)
        else: 
            st.error(f"âŒ è¯»å–å¤±è´¥ï¼šæœªæ‰¾åˆ° Sheet '{SHEET_CONFIG['ratios']}'")

    elif analysis_page == "(äº”) ç›ˆåˆ©èƒ½åŠ›åˆ†æ":
        df_profit, d_labels, err = get_clean_data(SHEET_CONFIG["profit"])
        if df_profit is not None:
            process_profitability_tab(df_profit, word_data_list, d_labels)
        else: st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{err}")
