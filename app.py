import streamlit as st
import pandas as pd
import re
from docx import Document
import io

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="è´¢åŠ¡æŠ¥å‘Šè‡ªåŠ¨åŒ–ç”Ÿæˆå™¨", 
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š è´¢åŠ¡åˆ†ææŠ¥å‘Šè‡ªåŠ¨åŒ–åŠ©æ‰‹")
st.markdown("""
**ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š**
1. ä¸Šä¼  **Excel åº•ç¨¿**ï¼ˆå¿…é¡»ï¼‰ã€‚
2. ä¸Šä¼  **Word é™„æ³¨**ï¼ˆå¯é€‰ï¼Œ**æ”¯æŒåŒæ—¶ä¼ å¤šä¸ª**ï¼Œå¦‚ï¼š23å¹´é™„æ³¨+24å¹´é™„æ³¨ï¼‰ã€‚
3. ç³»ç»Ÿä¼šè‡ªåŠ¨è®¡ç®—æ•°æ®ï¼Œç”Ÿæˆ **æ•°æ®åˆ†æè¯­æ–™**ã€‚
4. ç‚¹å‡»å³ä¸Šè§’çš„ **ğŸ“„ å¤åˆ¶æŒ‰é’®**ï¼Œå‘é€ç»™ AI æˆ–ç›´æ¥ä½¿ç”¨ã€‚
""")

# ================= 2. ä¾§è¾¹æ ï¼šæ–‡ä»¶ä¸Šä¼  =================
with st.sidebar:
    st.header("ğŸ“‚ è¯·ä¸Šä¼ æ–‡ä»¶")
    
    # 1. Excel (å¿…é¡»)
    uploaded_excel = st.file_uploader("1. ä¸Šä¼  Excel åº•ç¨¿ (å¿…é¡»)", type=["xlsx", "xlsm"])
    
    # 2. Word (å¯é€‰ï¼Œæ”¯æŒå¤šæ–‡ä»¶)
    uploaded_word_files = st.file_uploader(
        "2. ä¸Šä¼  Word é™„æ³¨ (å¯é€‰)", 
        type=["docx"], 
        accept_multiple_files=True, # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå…è®¸é€‰å¤šä¸ªæ–‡ä»¶
        help="æ”¯æŒæŒ‰ä½ Ctrl/Command é”®å¤šé€‰æ–‡ä»¶ï¼Œæˆ–è€…å¤šæ¬¡æ‹–å…¥ã€‚"
    )
    
    st.info("ğŸ’¡ æç¤ºï¼šæ•°æ®åªåœ¨æµè§ˆå™¨æœ¬åœ°å¤„ç†ï¼Œä¸ä¼šä¸Šä¼ ç»™ç¬¬ä¸‰æ–¹ AIï¼Œç»å¯¹å®‰å…¨ã€‚")
    
    # å…è®¸ç”¨æˆ·è°ƒæ•´è¡¨å¤´è¡Œ
    header_row = st.number_input("Excelè¡¨å¤´æ‰€åœ¨è¡Œ (é»˜è®¤2ï¼Œå³ç¬¬3è¡Œ)", value=2, min_value=0)

# ================= 3. æ ¸å¿ƒé€»è¾‘å‡½æ•° =================

def load_single_word(file_obj):
    """è¯»å–å•ä¸ª Word æ–‡ä»¶æµ"""
    try:
        doc = Document(file_obj)
        full_text = []
        for para in doc.paragraphs:
            clean = para.text.strip()
            if len(clean) > 5:
                full_text.append(clean)
        return "\n".join(full_text)
    except Exception as e:
        return f"ï¼ˆæ–‡ä»¶ {file_obj.name} è¯»å–å¤±è´¥: {e}ï¼‰"

def find_context(subject, full_text):
    """RAG æ£€ç´¢"""
    if not full_text: return ""
    clean_sub = subject.replace(" ", "")
    idx = full_text.find(clean_sub)
    if idx == -1: return "ï¼ˆé™„æ³¨ä¸­æœªæ£€ç´¢åˆ°è¯¥ç§‘ç›®åç§°ï¼‰"
    # æˆªå–å‰åæ–‡ï¼Œå› ä¸ºæ–‡æœ¬å˜é•¿äº†ï¼Œç¨å¾®æ‰©å¤§ä¸€ç‚¹èŒƒå›´
    start = max(0, idx - 600)
    end = min(len(full_text), idx + 1200) 
    return full_text[start:end].replace('\n', ' ')

def clean_date_label(header_str):
    """æ¸…æ´—æ—¥æœŸæ ‡ç­¾"""
    s = str(header_str).replace('\n', '')
    year = re.search(r'(\d{4})', s)
    y_str = year.group(1) if year else "T"
    suffix = "6æœˆæœ«" if ("ä¸€æœŸ" in s or "6æœˆ" in s) else "å¹´æœ«"
    return f"{y_str}å¹´{suffix}"

# å®‰å…¨è®¡ç®—å æ¯”å‡½æ•°
def safe_pct(num, denom):
    return (num / denom * 100) if denom != 0 else 0.0

# ================= 4. ä¸»ç¨‹åºé€»è¾‘ =================

if uploaded_excel:
    st.success("âœ… åˆ†æå®Œæˆï¼å·²ç”Ÿæˆæ•°æ®ç»¼è¿°ä¸ç§‘ç›®åˆ†æï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹ç»“æœã€‚")
    
    try:
        # --- 1. è¯»å–å¹¶å¤„ç† Excel ---
        df = pd.read_excel(uploaded_excel, sheet_name='1.åˆå¹¶èµ„äº§è¡¨', header=header_row)
        df = df.iloc[:, [0, 4, 5, 6]]
        
        orig_cols = df.columns.tolist()
        d_t = clean_date_label(orig_cols[1])
        d_t1 = clean_date_label(orig_cols[2])
        d_t2 = clean_date_label(orig_cols[3])
        
        df.columns = ['ç§‘ç›®', 'T', 'T_1', 'T_2']
        
        # æ•°æ®æ¸…æ´—
        df = df.dropna(subset=['ç§‘ç›®'])
        df['ç§‘ç›®'] = df['ç§‘ç›®'].astype(str).str.strip()
        for c in ['T', 'T_1', 'T_2']:
            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
            
        df.set_index('ç§‘ç›®', inplace=True)
        
        # æå–å…³é”®è¡Œ
        try:
            total_assets = df[df.index.str.contains('èµ„äº§æ€»è®¡|èµ„äº§æ€»é¢')].iloc[0]
            curr_assets = df[df.index.str.contains('æµåŠ¨èµ„äº§åˆè®¡')].iloc[0]
            non_curr_assets = df[df.index.str.contains('éæµåŠ¨èµ„äº§åˆè®¡')].iloc[0]
        except IndexError:
            st.error("âŒ æœªæ‰¾åˆ° 'èµ„äº§æ€»è®¡' ç­‰å…³é”®è¡Œï¼Œè¯·æ£€æŸ¥ Excel ç§‘ç›®åç§°ã€‚")
            st.stop()
            
        # è®¡ç®— T æœŸå æ¯”
        if total_assets['T'] != 0:
            df['å æ¯”_T'] = df['T'] / total_assets['T']
        else:
            df['å æ¯”_T'] = 0.0
        
        # --- 2. å¤„ç† Word (æ”¯æŒå¤šæ–‡ä»¶åˆå¹¶) ---
        word_text_all = ""
        has_word = False
        
        if uploaded_word_files:
            has_word = True
            # å¾ªç¯è¯»å–æ¯ä¸ªæ–‡ä»¶
            for w_file in uploaded_word_files:
                content = load_single_word(w_file)
                # ğŸ”¥ æ‹¼æ¥æ—¶åŠ ä¸Šæ–‡ä»¶åæ ‡è®°ï¼Œæ–¹ä¾¿åŒºåˆ†æ¥æº
                word_text_all += f"\n\nã€--- ä»¥ä¸‹å†…å®¹æ¥è‡ªæ–‡ä»¶ï¼š{w_file.name} ---ã€‘\n"
                word_text_all += content
        else:
            # å¦‚æœæ²¡ä¼ æ–‡ä»¶ï¼Œä¿æŒç©ºå­—ç¬¦ä¸²
            pass

        # ================= 5. ç»“æœå±•ç¤º =================
        
        tab1, tab2, tab3 = st.tabs(["ğŸ“‹ 1. èµ„äº§æ˜ç»†", "ğŸ“ 2. ç»¼è¿°æ–‡æ¡ˆ", "ğŸ¤– 3. é‡ç‚¹ç§‘ç›®åˆ†æ"])
        
        # --- Tab 1: æ˜ç»†è¡¨ ---
        with tab1:
            st.markdown("### èµ„äº§ç»“æ„æ˜ç»†")
            display_df = df.copy()
            display_df['å æ¯”_T(%)'] = (display_df['å æ¯”_T'] * 100).apply(lambda x: f"{x:.2f}%")
            st.dataframe(
                display_df[['T', 'T_1', 'T_2', 'å æ¯”_T(%)']].style.format(
                    subset=['T', 'T_1', 'T_2'], 
                    formatter="{:,.2f}"
                )
            )

        # --- Tab 2: ç»¼è¿°æ–‡æ¡ˆ ---
        with tab2:
            st.subheader("èµ„äº§ç»“æ„æ€»ä½“åˆ†æ")
            st.markdown("ğŸ‘‡ **ç›´æ¥å¤åˆ¶åˆ°æŠ¥å‘Šï¼š**")
            
            exclude = ['åˆè®¡', 'æ€»è®¡', 'æ€»é¢']
            detail_df = df[~df.index.str.contains('|'.join(exclude))]
            top_5 = detail_df.sort_values(by='T', ascending=False).head(5).index.tolist()
            top_5_str = "ã€".join(top_5)
            
            text_overview = (
                f"æŠ¥å‘ŠæœŸå†…ï¼Œå‘è¡Œäººèµ„äº§æ€»é¢åˆ†åˆ«ä¸º{total_assets['T_2']:,.2f}ä¸‡å…ƒã€{total_assets['T_1']:,.2f}ä¸‡å…ƒå’Œ{total_assets['T']:,.2f}ä¸‡å…ƒã€‚\n\n"
                f"å…¶ä¸­ï¼ŒæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{curr_assets['T_2']:,.2f}ä¸‡å…ƒã€{curr_assets['T_1']:,.2f}ä¸‡å…ƒå’Œ{curr_assets['T']:,.2f}ä¸‡å…ƒï¼Œ"
                f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(curr_assets['T_2'], total_assets['T_2']):.2f}%ã€"
                f"{safe_pct(curr_assets['T_1'], total_assets['T_1']):.2f}%å’Œ"
                f"{safe_pct(curr_assets['T'], total_assets['T']):.2f}%ï¼›\n\n"
                f"éæµåŠ¨èµ„äº§é‡‘é¢åˆ†åˆ«ä¸º{non_curr_assets['T_2']:,.2f}ä¸‡å…ƒã€{non_curr_assets['T_1']:,.2f}ä¸‡å…ƒå’Œ{non_curr_assets['T']:,.2f}ä¸‡å…ƒï¼Œ"
                f"å æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{safe_pct(non_curr_assets['T_2'], total_assets['T_2']):.2f}%ã€"
                f"{safe_pct(non_curr_assets['T_1'], total_assets['T_1']):.2f}%å’Œ"
                f"{safe_pct(non_curr_assets['T'], total_assets['T']):.2f}%ã€‚\n\n"
                f"åœ¨æ€»èµ„äº§æ„æˆä¸­ï¼Œå…¬å¸èµ„äº§ä¸»è¦ä¸º **{top_5_str}** ç­‰ã€‚"
            )
            st.code(text_overview, language='text')

        # --- Tab 3: AI æŒ‡ä»¤ (çº¯å‡€ç‰ˆ) ---
        with tab3:
            st.subheader("ğŸ¤– é‡ç‚¹ç§‘ç›®åˆ†ææ•°æ® (Copilot æ¨¡å¼)")
            st.caption("ğŸ‘‰ ç‚¹å‡»ä»£ç å—å³ä¸Šè§’çš„ **ğŸ“„ å¤åˆ¶**ï¼Œç²˜è´´ç»™ DeepSeek æˆ– ChatGPTã€‚")
            
            if not has_word:
                st.info("â„¹ï¸ æœªä¸Šä¼  Wordï¼Œç”Ÿæˆã€çº¯æ•°æ®åˆ†æã€‘ã€‚")
            
            major_subjects = detail_df[detail_df['å æ¯”_T'] > 0.01].index.tolist()
            
            for subject in major_subjects:
                row = df.loc[subject]
                v_t2, v_t1, v_t = row['T_2'], row['T_1'], row['T']
                r_t2 = safe_pct(v_t2, total_assets['T_2'])
                r_t1 = safe_pct(v_t1, total_assets['T_1'])
                r_t = safe_pct(v_t, total_assets['T'])
                
                diff = v_t - v_t1
                pct = safe_pct(diff, v_t1)
                
                if diff >= 0:
                    direction = "å¢åŠ "
                    pct_label = "å¢å¹…"
                else:
                    direction = "å‡å°‘"
                    pct_label = "é™å¹…"
                
                prompt_base = f"""ã€ä»»åŠ¡ã€‘ï¼šè¯·åˆ†æâ€œ{subject}â€çš„å˜åŠ¨æƒ…å†µã€‚

ã€1. è´¢åŠ¡å…·ä½“ç§‘ç›®æ•°æ® (Trend)ã€‘
{d_t2}ã€{d_t1}åŠ{d_t}ï¼Œå‘è¡Œäºº{subject}ä½™é¢åˆ†åˆ«ä¸º{v_t2:,.2f}ä¸‡å…ƒã€{v_t1:,.2f}ä¸‡å…ƒå’Œ{v_t:,.2f}ä¸‡å…ƒï¼Œå æ€»èµ„äº§çš„æ¯”ä¾‹åˆ†åˆ«ä¸º{r_t2:.2f}%ã€{r_t1:.2f}%å’Œ{r_t:.2f}%ã€‚

ã€2. è´¢åŠ¡ç¡¬æ•°æ®å˜åŠ¨ (Analysis)ã€‘
æˆªè‡³{d_t}ï¼Œå‘è¡Œäºº{subject}è¾ƒ{d_t1}{direction}{abs(diff):,.2f}ä¸‡å…ƒï¼Œ{pct_label}ä¸º{abs(pct):.2f}%ã€‚"""

                if has_word:
                    # åœ¨åˆå¹¶åçš„æ‰€æœ‰æ–‡æœ¬ä¸­æŸ¥æ‰¾
                    context = find_context(subject, word_text_all)
                    prompt_final = prompt_base + f"""

ã€3. Word é™„æ³¨è½¯ä¿¡æ¯ (Context)ã€‘
{context}

ã€4. å†™ä½œæŒ‡ä»¤ã€‘
è¯·ç»“åˆä¸Šè¿°æ•°æ®å’Œé™„æ³¨ï¼Œåˆ†æå˜åŠ¨åŸå› ï¼ˆå³â€œä¸»è¦ç³»...æ‰€è‡´â€ï¼‰ã€‚å¦‚æœé™„æ³¨ä¸­æœªæåŠï¼Œè¯·å†™â€œä¸»è¦ç³»ä¸šåŠ¡è§„æ¨¡å˜åŠ¨æ‰€è‡´â€ã€‚"""
                else:
                    prompt_final = prompt_base 

                with st.expander(f"ğŸ“Œ {subject} (å æ¯” {r_t:.2f}%)"):
                    st.code(prompt_final, language='text')

    except Exception as e:
        st.error(f"è§£æå‡ºé”™: {e}")
        st.info("è¯·æ£€æŸ¥ Excel æ ¼å¼æ˜¯å¦ä¸æ¨¡ç‰ˆä¸€è‡´ã€‚")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
